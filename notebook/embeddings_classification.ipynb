{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccc25715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/scratch/cinthiasouza/mv-text-summarizer')\n",
    "\n",
    "import glob, os\n",
    "import pandas as pd\n",
    "import json\n",
    "import spacy\n",
    "import nltk\n",
    "import numpy as np\n",
    "import json\n",
    "#import smogn\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "from pysbd.utils import PySBDFactory\n",
    "import math\n",
    "\n",
    "from sumeval.metrics.rouge import RougeCalculator\n",
    "rouge = RougeCalculator(stopwords=True, lang=\"en\")\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from timeit import default_timer as timer \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "#from tensorflow.keras.models import model_from_json\n",
    "\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('maxent_ne_chunker')\n",
    "#nltk.download('words')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "\n",
    "#import en_core_web_sm\n",
    "#nlp_md = en_core_web_sm.load()\n",
    "\n",
    "#import en_core_web_md\n",
    "#nlp_md = en_core_web_md.load()\n",
    "\n",
    "#!python -m spacy download en_core_web_sm\n",
    "nlp_sm = spacy.load('en_core_web_sm')\n",
    "\n",
    "#import en_core_web_sm\n",
    "#nlp_md = en_core_web_sm.load()y\n",
    "\n",
    "#import en_core_web_md\n",
    "#nlp_md = en_core_web_md.load()\n",
    "#!python -m spacy download en_core_web_md\n",
    "nlp_md = spacy.load('en_core_web_md')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "path_base = \"/scratch/cinthiasouza/mv-text-summarizer\"\n",
    "path_to_read=\"/scratch/cinthiasouza/mv-text-summarizer/result_/{}/{}_*.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a5dea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src import preprocess\n",
    "from src import extract_features\n",
    "from src import tokenizer\n",
    "from src import create_features_df\n",
    "from src import transform_data\n",
    "from src import loader\n",
    "from src import utils\n",
    "from src import ensemble_tree_models\n",
    "from src import tunning_hyperparametrs as th\n",
    "#from src import mlp_regressor\n",
    "#from src import mlp_classifier\n",
    "from src import summarization\n",
    "from src import normalization\n",
    "from src import ensemble_tree_models as classifiers\n",
    "from src import utils_classification as utils_clf\n",
    "from src import evaluate_classifiers as ev\n",
    "from src import prepare_data\n",
    "from src import display_results as dr\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "#from src import pipeline_extract_features as pef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49cba1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, InputLayer, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9d9b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset5_{}.pkl'.format('features'), 'rb') as fp:\n",
    "    dataset = pickle.load(fp)\n",
    "\n",
    "columns_name = ['text_rank', 'lex_rank', 'count_one_gram', 'count_two_gram',\n",
    "       'count_three_gram', 'count_article_keywords', 'tf-isf', 'pos_score', 'ner_score']\n",
    "\n",
    "sections=['introduction', 'materials', 'conclusion']\n",
    "\n",
    "folder_to_save = 'models_v5'\n",
    "\n",
    "path_to_save = \"/scratch/cinthiasouza/mv-text-summarizer/notebook/{}\".format(folder_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98febf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(sentence):\n",
    "\n",
    "    doc = nlp_md(sentence)\n",
    "    return doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1451c38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_to_save = 'models_v4'\n",
    "path_to_save = \"/scratch/cinthiasouza/mv-text-summarizer/notebook/{}\".format(folder_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6908ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "section = \"introduction\"\n",
    "\n",
    "features = dataset[section][4][['sentences', 'articles', 'rouge_1', 'bin']]\n",
    "features = features_intro.reset_index(drop=True)\n",
    "\n",
    "X_train, y_train = RandomUnderSampler().fit_resample(features[['sentences', 'articles', 'rouge_1']],\n",
    "                                                     features['bin'])\n",
    "\n",
    "embeddings = [create_embeddings(row['sentences']) for idx, row in X_train.iterrows()]\n",
    "df = pd.DataFrame(embeddings)\n",
    "df['label'] = y_train\n",
    "\n",
    "df.to_csv(\"{}/embed_{}_train.csv\".format (path_to_save, section), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3bea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "section = \"materials\"\n",
    "\n",
    "features = dataset[section][4][['sentences', 'articles', 'rouge_1', 'bin']]\n",
    "features = features_intro.reset_index(drop=True)\n",
    "\n",
    "X_train, y_train = RandomUnderSampler().fit_resample(features[['sentences', 'articles', 'rouge_1']],\n",
    "                                                     features['bin'])\n",
    "\n",
    "embeddings = [create_embeddings(row['sentences']) for idx, row in X_train.iterrows()]\n",
    "df = pd.DataFrame(embeddings)\n",
    "df['label'] = y_train\n",
    "\n",
    "df.to_csv(\"{}/embed_{}_train.csv\".format (path_to_save, section), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6733324",
   "metadata": {},
   "outputs": [],
   "source": [
    "section = \"conclusion\"\n",
    "\n",
    "features = dataset[section][4][['sentences', 'articles', 'rouge_1', 'bin']]\n",
    "features = features_intro.reset_index(drop=True)\n",
    "\n",
    "X_train, y_train = RandomUnderSampler().fit_resample(features[['sentences', 'articles', 'rouge_1']],\n",
    "                                                     features['bin'])\n",
    "\n",
    "embeddings = [create_embeddings(row['sentences']) for idx, row in X_train.iterrows()]\n",
    "df = pd.DataFrame(embeddings)\n",
    "df['label'] = y_train\n",
    "\n",
    "df.to_csv(\"{}/embed_{}_train.csv\".format (path_to_save, section), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad36da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "section = \"introduction\"\n",
    "\n",
    "features = dataset[section][5][['sentences', 'articles', 'rouge_1', 'bin']]\n",
    "features = features_intro.reset_index(drop=True)\n",
    "\n",
    "X_train, y_train = RandomUnderSampler().fit_resample(features[['sentences', 'articles', 'rouge_1']],\n",
    "                                                     features['bin'])\n",
    "\n",
    "embeddings = [create_embeddings(row['sentences']) for idx, row in X_train.iterrows()]\n",
    "df = pd.DataFrame(embeddings)\n",
    "df['label'] = y_train\n",
    "\n",
    "df.to_csv(\"{}/embed_{}_test.csv\".format (path_to_save, section), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792e4958",
   "metadata": {},
   "outputs": [],
   "source": [
    "section = \"materials\"\n",
    "\n",
    "features = dataset[section][5][['sentences', 'articles', 'rouge_1', 'bin']]\n",
    "features = features_intro.reset_index(drop=True)\n",
    "\n",
    "X_train, y_train = RandomUnderSampler().fit_resample(features[['sentences', 'articles', 'rouge_1']],\n",
    "                                                     features['bin'])\n",
    "\n",
    "embeddings = [create_embeddings(row['sentences']) for idx, row in X_train.iterrows()]\n",
    "df = pd.DataFrame(embeddings)\n",
    "df['label'] = y_train\n",
    "\n",
    "df.to_csv(\"{}/embed_{}_test.csv\".format (path_to_save, section), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca2d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "section = \"conclusion\"\n",
    "\n",
    "features = dataset[section][5][['sentences', 'articles', 'rouge_1', 'bin']]\n",
    "features = features_intro.reset_index(drop=True)\n",
    "\n",
    "X_train, y_train = RandomUnderSampler().fit_resample(features[['sentences', 'articles', 'rouge_1']],\n",
    "                                                     features['bin'])\n",
    "\n",
    "embeddings = [create_embeddings(row['sentences']) for idx, row in X_train.iterrows()]\n",
    "df = pd.DataFrame(embeddings)\n",
    "df['label'] = y_train\n",
    "\n",
    "df.to_csv(\"{}/embed_{}_test.csv\".format (path_to_save, section), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9f1d1367",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"{}/embed_introduction_train.csv\".format(path_to_save), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
