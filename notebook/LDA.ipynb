{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b3caef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparsesvd import sparsesvd\n",
    "from scipy.sparse import csc_matrix\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5bbddf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from gensim import corpora\n",
    "from gensim import matutils\n",
    "from gensim.models import LsiModel, LdaModel, RpModel, HdpModel, TfidfModel\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "5da64193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unicode(text):\n",
    "\n",
    "    text = str(text).encode(\"ascii\", \"ignore\")\n",
    "    text = text.decode()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "4d6feba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(document, en_stemmer, en_stopwords):\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    texts = [] \n",
    "    \n",
    "    for sentence in document:\n",
    "        \n",
    "        sentence = str(sentence).lower()\n",
    "        sentence = remove_unicode(sentence)\n",
    "        sentence_token = tokenizer.tokenize(sentence)\n",
    "        sentence_token = [en_stemmer.stem(i) for i in sentence_token if not i in en_stopwords]\n",
    "        texts.append(sentence_token)\n",
    "        \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "65c710fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_corpus(document):\n",
    "    \n",
    "    dictionary = corpora.Dictionary(document)\n",
    "    freq_matrix = [dictionary.doc2bow(doc) for doc in document]\n",
    "\n",
    "    return dictionary, freq_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "84ebc9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, doc_term_matrix, doc_clean, stop, start=2, step=3):\n",
    "\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    \n",
    "    for num_topics in range(start, stop, step):\n",
    "       \n",
    "        model = LsiModel(doc_term_matrix, num_topics=number_of_topics, id2word = dictionary)  # train model\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=doc_clean, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    \n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "58c8038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_V(model, freq_matrix):\n",
    "    \n",
    "    V = matutils.corpus2dense(model[freq_matrix], len(model.projection.s)).T / model.projection.s\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "fdbae4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(corpus_model, k):\n",
    "    \n",
    "    aux = []\n",
    "    for j, docv in enumerate(corpus_model):\n",
    "\n",
    "        for i in range(k):\n",
    "            \n",
    "            try:\n",
    "                aux.append([j, docv[i][0], docv[i][1]])\n",
    "            except IndexError:\n",
    "                pass\n",
    "    \n",
    "    name_columns = ['sentence', 'topic', 'weight']\n",
    "    df = pd.DataFrame(aux, columns=name_columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "522d8557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_ranking(df):\n",
    "    \n",
    "    ranking = {}\n",
    "    for i in range(k):\n",
    "        ranking[i] = df.loc[df['topic'] == i].sort_values('weight')['sentence'].tolist()\n",
    "        \n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "ffaf0afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sentences(ranking, n_sentences=2):\n",
    "\n",
    "    sentences = []\n",
    "    for key in ranking.keys():\n",
    "        count = 1 \n",
    "        for i in range(n_sentences):\n",
    "            \n",
    "            try:\n",
    "                sentence_id = ranking.get(key)[i]\n",
    "\n",
    "                if not sentence_id in sentences:\n",
    "                    sentences.append(ranking.get(key)[i])\n",
    "                elif not count == len(ranking.get(key)):\n",
    "                    sentences.append(ranking.get(key)[i+count])\n",
    "                count+=1\n",
    "            except IndexError:\n",
    "                pass\n",
    "            \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "c65687c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary(text_sent, sentences_id):\n",
    "    \n",
    "    summary = [text_sent[i] for i in sentences_id]\n",
    "    \n",
    "    return \" \".join(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "e063a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_topic_models(text, k=2, words=2, name_models=['lsi']):\n",
    "    \n",
    "    models = {}\n",
    "    corpus = {}\n",
    "    \n",
    "    en_stopwords = set(stopwords.words('english'))\n",
    "    en_stemmer = PorterStemmer()\n",
    "    \n",
    "    text_clean = preprocess_data(text, en_stemmer, en_stopwords)\n",
    "    dictionary, freq_matrix = prepare_corpus(text_clean)\n",
    "\n",
    "    for name_model in name_models:\n",
    "        \n",
    "        if name_model == 'lsi':\n",
    "            model = LsiModel(freq_matrix, id2word=dictionary, num_topics=k)\n",
    "            models[name_model] = model\n",
    "        elif name_model == 'lda':\n",
    "            model = LdaModel(freq_matrix, id2word=dictionary, num_topics=k)\n",
    "            models[name_model] = model\n",
    "        elif name_model == 'hdp':\n",
    "            model = HdpModel(freq_matrix, id2word=dictionary)\n",
    "            models[name_model] = model\n",
    "            \n",
    "        corpus[name_model] = model[freq_matrix]\n",
    "\n",
    "    return models, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "8b5b1950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_summarization(corpus, name_model, n_sentences=2, k=2):\n",
    "    \n",
    "    df = format_data(corpus[name_model], k)\n",
    "    ranking = sentence_ranking(df)\n",
    "    sentences_id = get_top_sentences(ranking, n_sentences=n_sentences)\n",
    "    summary = create_summary(text, sentences_id)\n",
    "\n",
    "    return summary, ranking, sentences_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e19c1627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(section):\n",
    "    section='conclusion'\n",
    "\n",
    "    with open('dataset6_{}.pkl'.format('features'), 'rb') as fp:\n",
    "        dataset = pickle.load(fp)\n",
    "    \n",
    "    train = dataset[section][4][['sentences', 'articles', 'rouge_1']]\n",
    "    test = dataset[section][5][['sentences', 'articles', 'rouge_1']]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da9d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_data(section)\n",
    "articles_id = pd.unique(train['articles'])\n",
    "\n",
    "summaries = {'article_id': [], 'summary': [], 'sentences_id': []}\n",
    "\n",
    "test['sentences'] = test['sentences'].astype('str')\n",
    "\n",
    "for article_id in articles_id:\n",
    "\n",
    "    #print(article_id)\n",
    "    aux = test.loc[train['articles'] == article_id]\n",
    "    \n",
    "    text = aux['sentences'].tolist()\n",
    "    models, corpus = main_topic_models(text, k=2, words=2, name_models=['lsi', 'lda'])\n",
    "    summary, _, sentences_id = main_summarization(corpus, name_model='lda', n_sentences=2, k=2)\n",
    "    \n",
    "    summaries['summary'].append(summary)\n",
    "    summaries['article_id'].append(article_id)\n",
    "    summaries['sentences_id'].append(sentences_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "bec0e76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = pd.DataFrame(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "fc837e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = pd.DataFrame(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "3c11e875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>summary</th>\n",
       "      <th>sentences_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PMC2836490.json</td>\n",
       "      <td>Cannula placement was confirmed at the end of ...</td>\n",
       "      <td>[3, 2, 9, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PMC2692135.json</td>\n",
       "      <td>Examining the prevalence of social anxiety acr...</td>\n",
       "      <td>[15, 7, 10, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PMC2940415.json</td>\n",
       "      <td>Forty eight adult and pediatric CF patients wi...</td>\n",
       "      <td>[0, 3, 4, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PMC6019182.json</td>\n",
       "      <td>our findings identify the presence of intratum...</td>\n",
       "      <td>[6, 5, 2, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PMC2891222.json</td>\n",
       "      <td>Subchondral bone marrow edema like lesions (BM...</td>\n",
       "      <td>[0, 9, 4, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10451</th>\n",
       "      <td>PMC6980738.json</td>\n",
       "      <td>10.1016/j.ygyno.2019.11.002 31776037</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10452</th>\n",
       "      <td>PMC6986304.json</td>\n",
       "      <td>After the occurrence of SCI in rats, the addit...</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10453</th>\n",
       "      <td>PMC6986779.json</td>\n",
       "      <td>31946748 Functional LGE imaging allows clear d...</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10454</th>\n",
       "      <td>PMC6994319.json</td>\n",
       "      <td>Over ten years after CDCâs revised recommend...</td>\n",
       "      <td>[0, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10455</th>\n",
       "      <td>PMC6999072.json</td>\n",
       "      <td>The correlation between the UPSIS 17 and the l...</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10456 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            article_id                                            summary  \\\n",
       "0      PMC2836490.json  Cannula placement was confirmed at the end of ...   \n",
       "1      PMC2692135.json  Examining the prevalence of social anxiety acr...   \n",
       "2      PMC2940415.json  Forty eight adult and pediatric CF patients wi...   \n",
       "3      PMC6019182.json  our findings identify the presence of intratum...   \n",
       "4      PMC2891222.json  Subchondral bone marrow edema like lesions (BM...   \n",
       "...                ...                                                ...   \n",
       "10451  PMC6980738.json               10.1016/j.ygyno.2019.11.002 31776037   \n",
       "10452  PMC6986304.json  After the occurrence of SCI in rats, the addit...   \n",
       "10453  PMC6986779.json  31946748 Functional LGE imaging allows clear d...   \n",
       "10454  PMC6994319.json  Over ten years after CDCâs revised recommend...   \n",
       "10455  PMC6999072.json  The correlation between the UPSIS 17 and the l...   \n",
       "\n",
       "         sentences_id  \n",
       "0        [3, 2, 9, 8]  \n",
       "1      [15, 7, 10, 2]  \n",
       "2        [0, 3, 4, 2]  \n",
       "3        [6, 5, 2, 4]  \n",
       "4       [0, 9, 4, 10]  \n",
       "...               ...  \n",
       "10451             [0]  \n",
       "10452       [0, 1, 0]  \n",
       "10453       [1, 0, 1]  \n",
       "10454       [0, 2, 1]  \n",
       "10455       [2, 1, 0]  \n",
       "\n",
       "[10456 rows x 3 columns]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_test = pd.DataFrame(summaries)\n",
    "lda_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
