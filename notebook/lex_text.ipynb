{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81ba0b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/scratch/cinthiasouza/mv-text-summarizer')\n",
    "\n",
    "from sumy.sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.sumy.summarizers.lsa import LsaSummarizer as SummarizerLsa\n",
    "from sumy.sumy.summarizers.lex_rank import LexRankSummarizer as SummarizerLex\n",
    "from sumy.sumy.summarizers.sum_basic import SumBasicSummarizer as SummarizerSumBasic\n",
    "from sumy.sumy.summarizers.text_rank import TextRankSummarizer  as SummarizerTextrank\n",
    "from sumy.sumy.summarizers.lsa import LsaSummarizer  as SummarizerLsa\n",
    "from sumy.sumy.nlp.stemmers import Stemmer\n",
    "from sumy.sumy.utils import get_stop_words\n",
    "\n",
    "LANGUAGE = \"english\"\n",
    "SENTENCES_COUNT=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8204b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df220351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "from src import tokenizer\n",
    "from src import extract_features\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src import preprocess\n",
    "from src import loader\n",
    "from src import utils\n",
    "from src import summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50b2bd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_text(text):\n",
    "    \n",
    "    xml = preprocess.format_xml(str(text))\n",
    "    text = preprocess.format_text(str(text), post_processing=False)\n",
    "\n",
    "    bibs = extract_features.get_citations(xml)\n",
    "    text = preprocess.replace_bib(text, bibs)\n",
    "    text = preprocess.format_text(text, post_processing=True)\n",
    "\n",
    "    soup = BeautifulSoup(text)\n",
    "    text = soup.get_text()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "082b9205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(df, SENTENCES_COUNT):\n",
    "    \n",
    "    sentences  = df.sort_values('ratings')[:SENTENCES_COUNT]['sentences']\n",
    "    \n",
    "    return \" \".join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50233994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summaries_lsa(text):\n",
    "\n",
    "    parser = PlaintextParser(text, Tokenizer(LANGUAGE))\n",
    "    stemmer = Stemmer(LANGUAGE)\n",
    "    summarizerlsa = SummarizerLsa(stemmer)\n",
    "    summarizerlsa.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "    result = summarizerlsa(parser.document, SENTENCES_COUNT)\n",
    "    \n",
    "    aux = result.copy()\n",
    "    summary_lsa = get_summary(aux, SENTENCES_COUNT)\n",
    "    \n",
    "    return summary_lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47566f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summaries_lex(text):\n",
    "\n",
    "    parser = PlaintextParser(text, Tokenizer(LANGUAGE))\n",
    "    \n",
    "    stemmer = Stemmer(LANGUAGE)\n",
    "    summarizerLex = SummarizerLex(stemmer)\n",
    "    summarizerLex.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "    result = summarizerLex(parser.document, SENTENCES_COUNT)\n",
    "    \n",
    "    aux = result.copy()\n",
    "    summary_lex = get_summary(aux, SENTENCES_COUNT)\n",
    "    \n",
    "    return summary_lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "917b3832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summaries_text(text):\n",
    "\n",
    "    parser = PlaintextParser(text, Tokenizer(LANGUAGE))\n",
    "    stemmer = Stemmer(LANGUAGE)\n",
    "    summarizerLex = SummarizerLex(stemmer)\n",
    "    summarizerLex.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "    result = summarizerLex(parser.document, SENTENCES_COUNT)\n",
    "    \n",
    "    aux = result.copy()\n",
    "    summary_text = get_summary(aux, SENTENCES_COUNT)\n",
    "    \n",
    "    return summary_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edfe978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dataset/dataset_{}.pkl'.format('features'), 'rb') as fp:\n",
    "    dataset = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab5e3a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "sections=['introduction', 'materials', 'conclusion', 'concat']\n",
    "\n",
    "for section in sections:\n",
    "    \n",
    "    grouped = dataset[section][5].groupby('articles')\n",
    "    texts = [' '.join(group['sentences']) for idx, group in grouped]\n",
    "    \n",
    "    df['articles'] =  [idx for idx, group in grouped]\n",
    "    df[section] = texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fafb902",
   "metadata": {},
   "outputs": [],
   "source": [
    "references_df = pd.read_csv(\"dataset/references_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96faf61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df = df.merge(references_df, on='articles')\n",
    "df.to_csv(\"baselines/lex_text_input.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14c5d231",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['introduction'] = df['introduction'].apply(pp_text)\n",
    "df['materials'] = df['materials'].apply(pp_text)\n",
    "df['conclusion'] = df['conclusion'].apply(pp_text)\n",
    "df['concat'] = df['concat'].apply(pp_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b2325a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_intro'] =  df['introduction'].apply(create_summaries_text)\n",
    "df['lex_intro'] =  df['introduction'].apply(create_summaries_lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46e42ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_mat'] =  df['materials'].apply(create_summaries_text)\n",
    "df['lex_mat'] =  df['materials'].apply(create_summaries_lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58656026",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_conc'] =  df['conclusion'].apply(create_summaries_text)\n",
    "df['lex_conc'] =  df['conclusion'].apply(create_summaries_lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0fd03d0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-65deac812bd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_concat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'concat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_summaries_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lex_concat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'concat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_summaries_lex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/cinthiasouza/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4136\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4138\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-1b5cfdc71694>\u001b[0m in \u001b[0;36mcreate_summaries_lex\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msummarizerLex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_stop_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLANGUAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarizerLex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSENTENCES_COUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cinthiasouza/mv-text-summarizer/sumy/sumy/utils.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cinthiasouza/mv-text-summarizer/sumy/sumy/parsers/plaintext.py\u001b[0m in \u001b[0;36mdocument\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mcurrent_paragraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_paragraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mparagraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParagraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cinthiasouza/mv-text-summarizer/sumy/sumy/parsers/plaintext.py\u001b[0m in \u001b[0;36m_to_sentences\u001b[0;34m(self, lines)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0msentence_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_sentence_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msentence_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cinthiasouza/mv-text-summarizer/sumy/sumy/parsers/plaintext.py\u001b[0m in \u001b[0;36m_to_sentence_objects\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_to_sentence_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/cinthiasouza/mv-text-summarizer/sumy/sumy/parsers/parser.py\u001b[0m in \u001b[0;36mtokenize_sentences\u001b[0;34m(self, paragraph)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtokenize_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparagraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPySBDFactory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cinthiasouza/anaconda3/lib/python3.8/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mblank\u001b[0;34m(name, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mblank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mLangClass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lang_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mLangClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cinthiasouza/anaconda3/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab, make_doc, max_length, meta, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmake_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mfactory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mmake_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_doc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cinthiasouza/anaconda3/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mcreate_tokenizer\u001b[0;34m(cls, nlp)\u001b[0m\n\u001b[1;32m    102\u001b[0m         )\n\u001b[1;32m    103\u001b[0m         \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         return Tokenizer(\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mrules\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrules\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mtokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer._load_special_tokenization\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mtokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer.add_special_case\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mvocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.make_fused_token\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mvocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.get_by_orth\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mvocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab._new_lexeme\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/scratch/cinthiasouza/anaconda3/lib/python3.8/site-packages/spacy/lang/lex_attrs.py\u001b[0m in \u001b[0;36mlower\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df['text_concat'] =  df['concat'].apply(create_summaries_text)\n",
    "df['lex_concat'] =  df['concat'].apply(create_summaries_lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a44ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_summaries(df, name_models, metrics):\n",
    "\n",
    "    vfunc = np.vectorize(summarization.rouge_metrics)\n",
    "    \n",
    "    for name_model in name_models:\n",
    "        \n",
    "        df['{}_r1'.format(name_model)],df['{}_r2'.format(name_model)],df['{}_rl'.format(name_model)] = vfunc(df[name_model], df['references'])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63657aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "689329ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"baselines/lex_text_summaries.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e98fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"baselines/lex_text_summaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26338b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=['rouge-1', 'rouge-2', 'rouge-l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4cd7d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_models = ['text_intro', 'lex_intro', 'text_mat', 'lex_mat', 'text_conc', 'lex_conc']\n",
    "result= summarization.evaluate_summariesv2(df, name_models, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1669a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_comb = pd.DataFrame()\n",
    "summaries_comb['references'] = result['references']\n",
    "summaries_comb['lex'] = result['lex_intro'] + result['lex_mat'] + result['lex_conc']\n",
    "summaries_comb['text'] = result['text_intro'] + result['text_mat'] + result['text_conc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8095215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_models = ['text', 'lex']\n",
    "result_comb = summarization.evaluate_summariesv2(summaries_comb, name_models, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8290862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>references</th>\n",
       "      <th>lex</th>\n",
       "      <th>text</th>\n",
       "      <th>text_rouge-1</th>\n",
       "      <th>text_rouge-2</th>\n",
       "      <th>text_rouge-l</th>\n",
       "      <th>lex_rouge-1</th>\n",
       "      <th>lex_rouge-2</th>\n",
       "      <th>lex_rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>context: evidence suggests that babies' fat ma...</td>\n",
       "      <td>Few studies have examined the long term conseq...</td>\n",
       "      <td>Few studies have examined the long term conseq...</td>\n",
       "      <td>0.326693</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.202958</td>\n",
       "      <td>0.326693</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.202958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summary information on the development and fun...</td>\n",
       "      <td>In humans, this region continues developing th...</td>\n",
       "      <td>In humans, this region continues developing th...</td>\n",
       "      <td>0.327381</td>\n",
       "      <td>0.071856</td>\n",
       "      <td>0.244997</td>\n",
       "      <td>0.327381</td>\n",
       "      <td>0.071856</td>\n",
       "      <td>0.244997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the present study examined ethnic, gender and ...</td>\n",
       "      <td>Adolescence is a period of significant develop...</td>\n",
       "      <td>Adolescence is a period of significant develop...</td>\n",
       "      <td>0.318471</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.216704</td>\n",
       "      <td>0.318471</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.216704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adenotonsillectomy (at) is among the most comm...</td>\n",
       "      <td>The groups also showed no baseline differences...</td>\n",
       "      <td>The groups also showed no baseline differences...</td>\n",
       "      <td>0.342391</td>\n",
       "      <td>0.027322</td>\n",
       "      <td>0.183325</td>\n",
       "      <td>0.342391</td>\n",
       "      <td>0.027322</td>\n",
       "      <td>0.183325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the performance of high sensitivity x ray imag...</td>\n",
       "      <td>Similar to Roos, several other authors have us...</td>\n",
       "      <td>Similar to Roos, several other authors have us...</td>\n",
       "      <td>0.426614</td>\n",
       "      <td>0.113949</td>\n",
       "      <td>0.226958</td>\n",
       "      <td>0.426614</td>\n",
       "      <td>0.113949</td>\n",
       "      <td>0.226958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>abnormal tau hyperphosphorylation and its aggr...</td>\n",
       "      <td>Indeed, NFTs are observed early in the pathoge...</td>\n",
       "      <td>Indeed, NFTs are observed early in the pathoge...</td>\n",
       "      <td>0.411379</td>\n",
       "      <td>0.070330</td>\n",
       "      <td>0.229748</td>\n",
       "      <td>0.411379</td>\n",
       "      <td>0.070330</td>\n",
       "      <td>0.229748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>research indicates that sleep duration and qua...</td>\n",
       "      <td>Morning chronotype may be related to successfu...</td>\n",
       "      <td>Morning chronotype may be related to successfu...</td>\n",
       "      <td>0.342222</td>\n",
       "      <td>0.066964</td>\n",
       "      <td>0.197288</td>\n",
       "      <td>0.342222</td>\n",
       "      <td>0.066964</td>\n",
       "      <td>0.197288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>background: as the prevalence of depression is...</td>\n",
       "      <td>. Hair cortisol may be a particularly useful b...</td>\n",
       "      <td>. Hair cortisol may be a particularly useful b...</td>\n",
       "      <td>0.341365</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.258946</td>\n",
       "      <td>0.341365</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.258946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>beats are among the basic units of perceptual ...</td>\n",
       "      <td>To test signal robustness, external time domai...</td>\n",
       "      <td>To test signal robustness, external time domai...</td>\n",
       "      <td>0.317949</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>0.175050</td>\n",
       "      <td>0.317949</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>0.175050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>a central bar repeatedly presented in alternat...</td>\n",
       "      <td>The mask can either precede the target (paraco...</td>\n",
       "      <td>The mask can either precede the target (paraco...</td>\n",
       "      <td>0.576531</td>\n",
       "      <td>0.312821</td>\n",
       "      <td>0.336305</td>\n",
       "      <td>0.576531</td>\n",
       "      <td>0.312821</td>\n",
       "      <td>0.336305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            references  \\\n",
       "0    context: evidence suggests that babies' fat ma...   \n",
       "1    summary information on the development and fun...   \n",
       "2    the present study examined ethnic, gender and ...   \n",
       "3    adenotonsillectomy (at) is among the most comm...   \n",
       "4    the performance of high sensitivity x ray imag...   \n",
       "..                                                 ...   \n",
       "919  abnormal tau hyperphosphorylation and its aggr...   \n",
       "920  research indicates that sleep duration and qua...   \n",
       "921  background: as the prevalence of depression is...   \n",
       "922  beats are among the basic units of perceptual ...   \n",
       "923  a central bar repeatedly presented in alternat...   \n",
       "\n",
       "                                                   lex  \\\n",
       "0    Few studies have examined the long term conseq...   \n",
       "1    In humans, this region continues developing th...   \n",
       "2    Adolescence is a period of significant develop...   \n",
       "3    The groups also showed no baseline differences...   \n",
       "4    Similar to Roos, several other authors have us...   \n",
       "..                                                 ...   \n",
       "919  Indeed, NFTs are observed early in the pathoge...   \n",
       "920  Morning chronotype may be related to successfu...   \n",
       "921  . Hair cortisol may be a particularly useful b...   \n",
       "922  To test signal robustness, external time domai...   \n",
       "923  The mask can either precede the target (paraco...   \n",
       "\n",
       "                                                  text  text_rouge-1  \\\n",
       "0    Few studies have examined the long term conseq...      0.326693   \n",
       "1    In humans, this region continues developing th...      0.327381   \n",
       "2    Adolescence is a period of significant develop...      0.318471   \n",
       "3    The groups also showed no baseline differences...      0.342391   \n",
       "4    Similar to Roos, several other authors have us...      0.426614   \n",
       "..                                                 ...           ...   \n",
       "919  Indeed, NFTs are observed early in the pathoge...      0.411379   \n",
       "920  Morning chronotype may be related to successfu...      0.342222   \n",
       "921  . Hair cortisol may be a particularly useful b...      0.341365   \n",
       "922  To test signal robustness, external time domai...      0.317949   \n",
       "923  The mask can either precede the target (paraco...      0.576531   \n",
       "\n",
       "     text_rouge-2  text_rouge-l  lex_rouge-1  lex_rouge-2  lex_rouge-l  \n",
       "0        0.064000      0.202958     0.326693     0.064000     0.202958  \n",
       "1        0.071856      0.244997     0.327381     0.071856     0.244997  \n",
       "2        0.051282      0.216704     0.318471     0.051282     0.216704  \n",
       "3        0.027322      0.183325     0.342391     0.027322     0.183325  \n",
       "4        0.113949      0.226958     0.426614     0.113949     0.226958  \n",
       "..            ...           ...          ...          ...          ...  \n",
       "919      0.070330      0.229748     0.411379     0.070330     0.229748  \n",
       "920      0.066964      0.197288     0.342222     0.066964     0.197288  \n",
       "921      0.129032      0.258946     0.341365     0.129032     0.258946  \n",
       "922      0.036082      0.175050     0.317949     0.036082     0.175050  \n",
       "923      0.312821      0.336305     0.576531     0.312821     0.336305  \n",
       "\n",
       "[924 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a03c1696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>references</th>\n",
       "      <th>lex</th>\n",
       "      <th>text</th>\n",
       "      <th>text_rouge-1</th>\n",
       "      <th>text_rouge-2</th>\n",
       "      <th>text_rouge-l</th>\n",
       "      <th>lex_rouge-1</th>\n",
       "      <th>lex_rouge-2</th>\n",
       "      <th>lex_rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>context: evidence suggests that babies' fat ma...</td>\n",
       "      <td>Few studies have examined the long term conseq...</td>\n",
       "      <td>Few studies have examined the long term conseq...</td>\n",
       "      <td>0.326693</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.202958</td>\n",
       "      <td>0.326693</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.202958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summary information on the development and fun...</td>\n",
       "      <td>In humans, this region continues developing th...</td>\n",
       "      <td>In humans, this region continues developing th...</td>\n",
       "      <td>0.327381</td>\n",
       "      <td>0.071856</td>\n",
       "      <td>0.244997</td>\n",
       "      <td>0.327381</td>\n",
       "      <td>0.071856</td>\n",
       "      <td>0.244997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the present study examined ethnic, gender and ...</td>\n",
       "      <td>Adolescence is a period of significant develop...</td>\n",
       "      <td>Adolescence is a period of significant develop...</td>\n",
       "      <td>0.318471</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.216704</td>\n",
       "      <td>0.318471</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.216704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adenotonsillectomy (at) is among the most comm...</td>\n",
       "      <td>The groups also showed no baseline differences...</td>\n",
       "      <td>The groups also showed no baseline differences...</td>\n",
       "      <td>0.342391</td>\n",
       "      <td>0.027322</td>\n",
       "      <td>0.183325</td>\n",
       "      <td>0.342391</td>\n",
       "      <td>0.027322</td>\n",
       "      <td>0.183325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the performance of high sensitivity x ray imag...</td>\n",
       "      <td>Similar to Roos, several other authors have us...</td>\n",
       "      <td>Similar to Roos, several other authors have us...</td>\n",
       "      <td>0.426614</td>\n",
       "      <td>0.113949</td>\n",
       "      <td>0.226958</td>\n",
       "      <td>0.426614</td>\n",
       "      <td>0.113949</td>\n",
       "      <td>0.226958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>abnormal tau hyperphosphorylation and its aggr...</td>\n",
       "      <td>Indeed, NFTs are observed early in the pathoge...</td>\n",
       "      <td>Indeed, NFTs are observed early in the pathoge...</td>\n",
       "      <td>0.411379</td>\n",
       "      <td>0.070330</td>\n",
       "      <td>0.229748</td>\n",
       "      <td>0.411379</td>\n",
       "      <td>0.070330</td>\n",
       "      <td>0.229748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>research indicates that sleep duration and qua...</td>\n",
       "      <td>Morning chronotype may be related to successfu...</td>\n",
       "      <td>Morning chronotype may be related to successfu...</td>\n",
       "      <td>0.342222</td>\n",
       "      <td>0.066964</td>\n",
       "      <td>0.197288</td>\n",
       "      <td>0.342222</td>\n",
       "      <td>0.066964</td>\n",
       "      <td>0.197288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>background: as the prevalence of depression is...</td>\n",
       "      <td>. Hair cortisol may be a particularly useful b...</td>\n",
       "      <td>. Hair cortisol may be a particularly useful b...</td>\n",
       "      <td>0.341365</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.258946</td>\n",
       "      <td>0.341365</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.258946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>beats are among the basic units of perceptual ...</td>\n",
       "      <td>To test signal robustness, external time domai...</td>\n",
       "      <td>To test signal robustness, external time domai...</td>\n",
       "      <td>0.317949</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>0.175050</td>\n",
       "      <td>0.317949</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>0.175050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>a central bar repeatedly presented in alternat...</td>\n",
       "      <td>The mask can either precede the target (paraco...</td>\n",
       "      <td>The mask can either precede the target (paraco...</td>\n",
       "      <td>0.576531</td>\n",
       "      <td>0.312821</td>\n",
       "      <td>0.336305</td>\n",
       "      <td>0.576531</td>\n",
       "      <td>0.312821</td>\n",
       "      <td>0.336305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            references  \\\n",
       "0    context: evidence suggests that babies' fat ma...   \n",
       "1    summary information on the development and fun...   \n",
       "2    the present study examined ethnic, gender and ...   \n",
       "3    adenotonsillectomy (at) is among the most comm...   \n",
       "4    the performance of high sensitivity x ray imag...   \n",
       "..                                                 ...   \n",
       "919  abnormal tau hyperphosphorylation and its aggr...   \n",
       "920  research indicates that sleep duration and qua...   \n",
       "921  background: as the prevalence of depression is...   \n",
       "922  beats are among the basic units of perceptual ...   \n",
       "923  a central bar repeatedly presented in alternat...   \n",
       "\n",
       "                                                   lex  \\\n",
       "0    Few studies have examined the long term conseq...   \n",
       "1    In humans, this region continues developing th...   \n",
       "2    Adolescence is a period of significant develop...   \n",
       "3    The groups also showed no baseline differences...   \n",
       "4    Similar to Roos, several other authors have us...   \n",
       "..                                                 ...   \n",
       "919  Indeed, NFTs are observed early in the pathoge...   \n",
       "920  Morning chronotype may be related to successfu...   \n",
       "921  . Hair cortisol may be a particularly useful b...   \n",
       "922  To test signal robustness, external time domai...   \n",
       "923  The mask can either precede the target (paraco...   \n",
       "\n",
       "                                                  text  text_rouge-1  \\\n",
       "0    Few studies have examined the long term conseq...      0.326693   \n",
       "1    In humans, this region continues developing th...      0.327381   \n",
       "2    Adolescence is a period of significant develop...      0.318471   \n",
       "3    The groups also showed no baseline differences...      0.342391   \n",
       "4    Similar to Roos, several other authors have us...      0.426614   \n",
       "..                                                 ...           ...   \n",
       "919  Indeed, NFTs are observed early in the pathoge...      0.411379   \n",
       "920  Morning chronotype may be related to successfu...      0.342222   \n",
       "921  . Hair cortisol may be a particularly useful b...      0.341365   \n",
       "922  To test signal robustness, external time domai...      0.317949   \n",
       "923  The mask can either precede the target (paraco...      0.576531   \n",
       "\n",
       "     text_rouge-2  text_rouge-l  lex_rouge-1  lex_rouge-2  lex_rouge-l  \n",
       "0        0.064000      0.202958     0.326693     0.064000     0.202958  \n",
       "1        0.071856      0.244997     0.327381     0.071856     0.244997  \n",
       "2        0.051282      0.216704     0.318471     0.051282     0.216704  \n",
       "3        0.027322      0.183325     0.342391     0.027322     0.183325  \n",
       "4        0.113949      0.226958     0.426614     0.113949     0.226958  \n",
       "..            ...           ...          ...          ...          ...  \n",
       "919      0.070330      0.229748     0.411379     0.070330     0.229748  \n",
       "920      0.066964      0.197288     0.342222     0.066964     0.197288  \n",
       "921      0.129032      0.258946     0.341365     0.129032     0.258946  \n",
       "922      0.036082      0.175050     0.317949     0.036082     0.175050  \n",
       "923      0.312821      0.336305     0.576531     0.312821     0.336305  \n",
       "\n",
       "[924 rows x 9 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08d03afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_rouge-1</th>\n",
       "      <th>text_rouge-2</th>\n",
       "      <th>text_rouge-l</th>\n",
       "      <th>lex_rouge-1</th>\n",
       "      <th>lex_rouge-2</th>\n",
       "      <th>lex_rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>924.000000</td>\n",
       "      <td>924.000000</td>\n",
       "      <td>924.000000</td>\n",
       "      <td>924.000000</td>\n",
       "      <td>924.000000</td>\n",
       "      <td>924.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.393194</td>\n",
       "      <td>0.116755</td>\n",
       "      <td>0.247540</td>\n",
       "      <td>0.393194</td>\n",
       "      <td>0.116755</td>\n",
       "      <td>0.247540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.072316</td>\n",
       "      <td>0.075820</td>\n",
       "      <td>0.056203</td>\n",
       "      <td>0.072316</td>\n",
       "      <td>0.075820</td>\n",
       "      <td>0.056203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.167750</td>\n",
       "      <td>0.006006</td>\n",
       "      <td>0.106008</td>\n",
       "      <td>0.167750</td>\n",
       "      <td>0.006006</td>\n",
       "      <td>0.106008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.345557</td>\n",
       "      <td>0.066057</td>\n",
       "      <td>0.210635</td>\n",
       "      <td>0.345557</td>\n",
       "      <td>0.066057</td>\n",
       "      <td>0.210635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.390023</td>\n",
       "      <td>0.099211</td>\n",
       "      <td>0.237153</td>\n",
       "      <td>0.390023</td>\n",
       "      <td>0.099211</td>\n",
       "      <td>0.237153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.435240</td>\n",
       "      <td>0.142999</td>\n",
       "      <td>0.270784</td>\n",
       "      <td>0.435240</td>\n",
       "      <td>0.142999</td>\n",
       "      <td>0.270784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.720403</td>\n",
       "      <td>0.536709</td>\n",
       "      <td>0.590199</td>\n",
       "      <td>0.720403</td>\n",
       "      <td>0.536709</td>\n",
       "      <td>0.590199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text_rouge-1  text_rouge-2  text_rouge-l  lex_rouge-1  lex_rouge-2  \\\n",
       "count    924.000000    924.000000    924.000000   924.000000   924.000000   \n",
       "mean       0.393194      0.116755      0.247540     0.393194     0.116755   \n",
       "std        0.072316      0.075820      0.056203     0.072316     0.075820   \n",
       "min        0.167750      0.006006      0.106008     0.167750     0.006006   \n",
       "25%        0.345557      0.066057      0.210635     0.345557     0.066057   \n",
       "50%        0.390023      0.099211      0.237153     0.390023     0.099211   \n",
       "75%        0.435240      0.142999      0.270784     0.435240     0.142999   \n",
       "max        0.720403      0.536709      0.590199     0.720403     0.536709   \n",
       "\n",
       "       lex_rouge-l  \n",
       "count   924.000000  \n",
       "mean      0.247540  \n",
       "std       0.056203  \n",
       "min       0.106008  \n",
       "25%       0.210635  \n",
       "50%       0.237153  \n",
       "75%       0.270784  \n",
       "max       0.590199  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_comb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5d2632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
