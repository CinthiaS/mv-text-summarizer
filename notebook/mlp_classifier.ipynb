{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b27135",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'show_config' from 'numpy' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c7dcaa89dce1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cinthiasouza/anaconda3/lib/python3.8/site-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cinthiasouza/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m from .utils._tags import (\n\u001b[1;32m     19\u001b[0m     \u001b[0m_DEFAULT_TAGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cinthiasouza/anaconda3/lib/python3.8/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmurmurhash\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmurmurhash3_32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cinthiasouza/anaconda3/lib/python3.8/site-packages/scipy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_config\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mshow_numpy_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mshow_numpy_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     raise ImportError(\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'show_config' from 'numpy' (unknown location)"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4ded1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7f6e861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: numpy: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!numpy --v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1960e3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, InputLayer, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2269a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ec3716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset6_{}.pkl'.format('features'), 'rb') as fp:\n",
    "    dataset = pickle.load(fp)\n",
    "\n",
    "path_to_save = \"/scratch/cinthiasouza/mv-text-summarizer/notebook/models_v6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83833afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_nn(model, name, path_to_save):\n",
    "    \n",
    "    model_json = model.to_json()\n",
    "\n",
    "    with open(\"{}/mlp_{}.json\".format(path_to_save, name), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "    model.save_weights(\"{}/mlp_{}.h5\".format(path_to_save, name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0077c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 20:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0901266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class TerminateOnBaseline(Callback):\n",
    "    \"\"\"Callback that terminates training when either acc or val_acc reaches a specified baseline\n",
    "    \"\"\"\n",
    "    def __init__(self, monitor='accuracy', baseline=0.9):\n",
    "        super(TerminateOnBaseline, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.baseline = baseline\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        acc = logs.get(self.monitor)\n",
    "        if acc is not None:\n",
    "            if acc >= self.baseline:\n",
    "                print('Epoch %d: Reached baseline, terminating training' % (epoch))\n",
    "                self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef452a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mlp = { \n",
    "    'introduction':  [ 0.2, 200, 8],\n",
    "    'materials':     [ 0.2, 200, 8],\n",
    "    'conclusion':  [ 0.2, 200, 8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "975c1eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7379/7379 [==============================] - 235s 24ms/step - loss: 1.1919 - precision_2: 0.5971 - val_loss: 0.7498 - val_precision_2: 0.6311\n",
      "Epoch 2/200\n",
      "7379/7379 [==============================] - 200s 27ms/step - loss: 1.1325 - precision_2: 0.5950 - val_loss: 0.7468 - val_precision_2: 0.5548\n",
      "Epoch 3/200\n",
      "7379/7379 [==============================] - 117s 16ms/step - loss: 1.1224 - precision_2: 0.5747 - val_loss: 0.7703 - val_precision_2: 0.5949\n",
      "Epoch 4/200\n",
      "7379/7379 [==============================] - 221s 30ms/step - loss: 1.1205 - precision_2: 0.5841 - val_loss: 0.8312 - val_precision_2: 0.5527\n",
      "Epoch 5/200\n",
      "7379/7379 [==============================] - 197s 27ms/step - loss: 1.1167 - precision_2: 0.5696 - val_loss: 0.7720 - val_precision_2: 0.5894\n",
      "Epoch 6/200\n",
      "7379/7379 [==============================] - 116s 16ms/step - loss: 1.1110 - precision_2: 0.5834 - val_loss: 0.7643 - val_precision_2: 0.5995\n",
      "Epoch 7/200\n",
      "7379/7379 [==============================] - 123s 17ms/step - loss: 1.1079 - precision_2: 0.5808 - val_loss: 0.7033 - val_precision_2: 0.6085\n",
      "Epoch 8/200\n",
      "7379/7379 [==============================] - 110s 15ms/step - loss: 1.1161 - precision_2: 0.5959 - val_loss: 0.7088 - val_precision_2: 0.5913\n",
      "Epoch 9/200\n",
      "7379/7379 [==============================] - 90s 12ms/step - loss: 1.1087 - precision_2: 0.5803 - val_loss: 0.7539 - val_precision_2: 0.5591\n",
      "Epoch 10/200\n",
      "7379/7379 [==============================] - 100s 14ms/step - loss: 1.1120 - precision_2: 0.5697 - val_loss: 0.7613 - val_precision_2: 0.5895\n",
      "Epoch 11/200\n",
      "7379/7379 [==============================] - 108s 15ms/step - loss: 1.1211 - precision_2: 0.5787 - val_loss: 0.7549 - val_precision_2: 0.6007\n",
      "Epoch 12/200\n",
      "7379/7379 [==============================] - 115s 16ms/step - loss: 1.1230 - precision_2: 0.5773 - val_loss: 0.8024 - val_precision_2: 0.5616\n",
      "Epoch 13/200\n",
      "7379/7379 [==============================] - 124s 17ms/step - loss: 1.1147 - precision_2: 0.5836 - val_loss: 0.7910 - val_precision_2: 0.5791\n",
      "Epoch 14/200\n",
      "7379/7379 [==============================] - 115s 16ms/step - loss: 1.1169 - precision_2: 0.5906 - val_loss: 0.7758 - val_precision_2: 0.6008\n",
      "Epoch 15/200\n",
      "7379/7379 [==============================] - 115s 16ms/step - loss: 1.1045 - precision_2: 0.6066 - val_loss: 0.7722 - val_precision_2: 0.5680\n",
      "Epoch 16/200\n",
      "7379/7379 [==============================] - 109s 15ms/step - loss: 1.1140 - precision_2: 0.5904 - val_loss: 0.8337 - val_precision_2: 0.5664\n",
      "Epoch 17/200\n",
      "7379/7379 [==============================] - 111s 15ms/step - loss: 1.1148 - precision_2: 0.5957 - val_loss: 0.8233 - val_precision_2: 0.5704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3175408070>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section='materials'\n",
    "\n",
    "X = dataset[section][0]\n",
    "y = dataset[section][2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(\n",
    "                learning_rate=0.001), metrics=[keras.metrics.Precision()])\n",
    "\n",
    "one_hot_label = to_categorical(y)\n",
    "\n",
    "test_size, epochs, batch_size =parameters_mlp.get(section)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, one_hot_label, stratify=one_hot_label, test_size=test_size)\n",
    "\n",
    "my_callbacks = [EarlyStopping(patience=20)]\n",
    "\n",
    "my_callbacks = [EarlyStopping(patience=10, restore_best_weights=True),\n",
    "                keras.callbacks.LearningRateScheduler(scheduler),\n",
    "                TerminateOnBaseline(monitor='val_precision', baseline=0.9)]\n",
    "\n",
    "\n",
    "model.fit(\n",
    "            np.array(X_train), np.array(y_train), validation_data=(X_valid,y_valid), epochs=epochs,\n",
    "             batch_size=batch_size, class_weight={0:6, 1:1}, callbacks=my_callbacks, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d42cf369",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=dataset[section][1]\n",
    "y_test =one_hot_label = to_categorical(dataset[section][3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "643a15c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open('{}/mlp_{}.json'.format(path_to_save, section), \"w\") as json_file:\n",
    "      json_file.write(model_json)\n",
    "model.save_weights('{}/mlp_{}.h5'.format(path_to_save, section))\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "85919452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "982/982 [==============================] - 10s 9ms/step - loss: 0.2994 - precision_27: 0.8786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29938286542892456, 0.8786105513572693]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
