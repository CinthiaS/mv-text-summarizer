{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45b27135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, concatenate, Dropout, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1960e3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, InputLayer, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28d2d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.math import exp\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 20:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6d40cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class TerminateOnBaseline(Callback):\n",
    "    \"\"\"Callback that terminates training when either acc or val_acc reaches a specified baseline\n",
    "    \"\"\"\n",
    "    def __init__(self, monitor='accuracy', baseline=0.9):\n",
    "        super(TerminateOnBaseline, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.baseline = baseline\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        acc = logs.get(self.monitor)\n",
    "        if acc is not None:\n",
    "            if acc >= self.baseline:\n",
    "                print('Epoch %d: Reached baseline, terminating training' % (epoch))\n",
    "                self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef452a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mlp = { \n",
    "    'introduction':  [ 0.2, 100, 8],\n",
    "    'materials':     [ 0.2, 100, 8],\n",
    "    'conclusion':  [ 0.2, 100, 8]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7402b3e",
   "metadata": {},
   "source": [
    "# MV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8974ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "section='conclusion'\n",
    "\n",
    "with open('dataset/dataset_{}.pkl'.format('features'), 'rb') as fp:\n",
    "    dataset = pickle.load(fp)\n",
    "\n",
    "X_features = dataset[section][0]\n",
    "y_features = dataset[section][2]\n",
    "\n",
    "\n",
    "columns = list(range(0, 383))\n",
    "columns = list(map(str, columns))\n",
    "\n",
    "folder_to_save = 'models_v1'\n",
    "path_to_save = \"/scratch/cinthiasouza/mv-text-summarizer/notebook/{}\".format(folder_to_save)\n",
    "\n",
    "X_embedd = pd.read_csv(\"dataset/embed_bert_{}_train.csv\".format(section))\n",
    "\n",
    "y_embedd = X_embedd['label']\n",
    "X_embedd = X_embedd[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68e37b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55620"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8e9d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(X_embedd.shape[1],), dtype='int32')\n",
    "\n",
    "S_1 = Dense(512, activation='tanh')(sequence_input)\n",
    "S_1 = Dense(512, activation='linear')(S_1)\n",
    "S_1 = Dense(512, activation=\"softmax\")(S_1)\n",
    "layer1 = S_1\n",
    "S_1 = Flatten()(S_1)\n",
    "\n",
    "sequence_input2 = Input(shape=(X_features.shape[1],), dtype='int32')\n",
    "\n",
    "S_2 = Dense(512, activation='tanh')(sequence_input2)\n",
    "S_2 = Dense(512, activation='linear')(S_2)\n",
    "S_2 = Dense(512, activation='softmax')(S_2)\n",
    "S_2 = Flatten()(S_2)\n",
    "\n",
    "S_3 = Dense(512, activation='tanh')(sequence_input2)\n",
    "S_3 = Dense(512, activation='linear')(S_3)\n",
    "S_3 = Dense(512, activation=\"softmax\")(S_3)\n",
    "S_3 = Flatten()(S_3)\n",
    "\n",
    "v_1 = S_1\n",
    "\n",
    "v_2_concat = concatenate([v_1, S_2])\n",
    "v_2 = Dense(512, activation='tanh')(v_2_concat)\n",
    "\n",
    "v_3_concat = concatenate([v_1, v_2, S_3])\n",
    "v_3 = Dense(512, activation='tanh')(v_3_concat)\n",
    "\n",
    "concat_layer = concatenate([v_1, v_2, v_3])\n",
    "\n",
    "perceptron_1 = Dense(256, activation='relu')(concat_layer)\n",
    "dropout1 = Dropout(.2)(perceptron_1)\n",
    "perceptron_2 = Dense(256, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(.2)(perceptron_2)\n",
    "perceptron_3 = Dense(512, activation='relu')(dropout2)\n",
    "dropout3 = Dropout(.3)(perceptron_3)\n",
    "perceptron_4 = Dense(512, activation='relu')(dropout3)\n",
    "dropout4 = Dropout(.3)(perceptron_4)\n",
    "perceptron_5 = Dense(1024, activation='relu')(dropout4)\n",
    "dropout5 = Dropout(.5)(perceptron_5)\n",
    "perceptron_6 = Dense(1024, activation='relu')(dropout5)\n",
    "dropout6 = Dropout(.5)(perceptron_6)\n",
    "perceptron_7 = Dense(512, activation='relu')(dropout6)\n",
    "dropout7 = Dropout(.3)(perceptron_7)\n",
    "perceptron_8 = Dense(256, activation='relu')(dropout7)\n",
    "dropout8 = Dropout(.3)(perceptron_8)\n",
    "perceptron_9 = Dense(128, activation='relu')(dropout8)\n",
    "dropout9 = Dropout(.2)(perceptron_3)\n",
    "\n",
    "preds = Dense(2, activation='sigmoid')(dropout9)\n",
    "\n",
    "model = Model(inputs=[sequence_input, sequence_input2], outputs=preds)\n",
    "\n",
    "my_callbacks = [keras.callbacks.LearningRateScheduler(scheduler),\n",
    "                TerminateOnBaseline(monitor='val_precision', baseline=0.9)]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(\n",
    "                learning_rate=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0f639e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12515/12515 [==============================] - 672s 53ms/step - loss: 0.6303 - accuracy: 0.6335 - val_loss: 0.6162 - val_accuracy: 0.6609\n",
      "Epoch 2/5\n",
      "12515/12515 [==============================] - 791s 63ms/step - loss: 0.6095 - accuracy: 0.6657 - val_loss: 0.6138 - val_accuracy: 0.6593\n",
      "Epoch 3/5\n",
      "12515/12515 [==============================] - 990s 79ms/step - loss: 0.6079 - accuracy: 0.6685 - val_loss: 0.6188 - val_accuracy: 0.6546\n",
      "Epoch 4/5\n",
      " 3707/12515 [=======>......................] - ETA: 14:09 - loss: 0.6125 - accuracy: 0.6623"
     ]
    }
   ],
   "source": [
    "one_hot_label = to_categorical(y_embedd)\n",
    "X_train_embedd, X_valid_embedd, y_train_embedd, y_valid_embedd = train_test_split(\n",
    "    X_embedd, one_hot_label, stratify=one_hot_label, shuffle=True, test_size=0.1)\n",
    "\n",
    "one_hot_label = to_categorical(y_features)\n",
    "X_train_features, X_valid_features, y_train_features, y_valid_features = train_test_split(\n",
    "    X_features, one_hot_label, stratify=one_hot_label, shuffle=True, test_size=0.1)\n",
    "\n",
    "history= model.fit(\n",
    "\tx=[X_train_embedd, X_train_features], y=y_train_features,\n",
    "\tepochs=5, validation_data=([X_valid_embedd, X_valid_features], y_valid_features),\n",
    "    callbacks=my_callbacks, shuffle=True, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45961131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "6258/6258 [==============================] - 347s 55ms/step - loss: 0.6625 - accuracy: 0.6233 - val_loss: 0.6586 - val_accuracy: 0.6341\n",
      "Epoch 2/3\n",
      "6258/6258 [==============================] - 320s 51ms/step - loss: 0.6476 - accuracy: 0.6255 - val_loss: 0.6350 - val_accuracy: 0.6458\n",
      "Epoch 3/3\n",
      "6258/6258 [==============================] - 319s 51ms/step - loss: 0.6465 - accuracy: 0.6088 - val_loss: 0.6476 - val_accuracy: 0.6471\n"
     ]
    }
   ],
   "source": [
    "one_hot_label = to_categorical(y_embedd)\n",
    "X_train_embedd, X_valid_embedd, y_train_embedd, y_valid_embedd = train_test_split(\n",
    "    X_embedd, one_hot_label, stratify=one_hot_label, shuffle=True, test_size=0.1)\n",
    "\n",
    "one_hot_label = to_categorical(y_features)\n",
    "X_train_features, X_valid_features, y_train_features, y_valid_features = train_test_split(\n",
    "    X_features, one_hot_label, stratify=one_hot_label, shuffle=True, test_size=0.1)\n",
    "\n",
    "history= model.fit(\n",
    "\tx=[X_train_embedd, X_train_features], y=y_train_features,\n",
    "\tepochs=3, validation_data=([X_valid_embedd, X_valid_features], y_valid_features),\n",
    "    callbacks=my_callbacks, shuffle=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "82d8a109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open('{}/mv_mlp_bert_{}.json'.format(path_to_save, section), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights('{}/mv_mlp_bert_{}.h5'.format(path_to_save, section))\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ef9b4d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1535/1535 [==============================] - 6s 4ms/step - loss: 0.5657 - precision_12: 0.6864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.565717339515686, 0.6863737106323242]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=[X_train_embedd, X_train_features], y=y_train_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
