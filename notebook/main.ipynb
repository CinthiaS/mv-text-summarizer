{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('mv-summarization': conda)"
  },
  "interpreter": {
   "hash": "5dd7fce1a8cb8d97b2536bbe54fd7faa274378c3acb961864d5bd989f2d52777"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/cinthia/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/cinthia/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/cinthia/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/cinthia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Collecting en_core_web_sm==2.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz (11.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.1 MB 5.2 MB/s \n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "Collecting en_core_web_md==2.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz (95.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 95.4 MB 9.3 MB/s \n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/media/cinthia/Dados/Mestrado/mv-text-summarizer')\n",
    "\n",
    "import glob, os\n",
    "import pandas as pd\n",
    "import json\n",
    "import spacy\n",
    "import nltk\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from sumeval.metrics.rouge import RougeCalculator\n",
    "from bs4 import BeautifulSoup\n",
    "from pysbd.utils import PySBDFactory\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from src import preprocess\n",
    "from src import extract_features\n",
    "from src import tokenizer\n",
    "from src import create_features_df\n",
    "from src import transform_data\n",
    "from src import loader\n",
    "from src import tunning_hyperparametrs as th\n",
    "from src import classifiers \n",
    "from src import neural_model\n",
    "from src import normalization\n",
    "\n",
    "rouge = RougeCalculator(stopwords=True, lang=\"en\")\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "\n",
    "!python -m spacy download en_core_web_sm\n",
    "nlp_sm = spacy.load('en_core_web_sm')\n",
    "\n",
    "!python -m spacy download en_core_web_md\n",
    "nlp_md = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(path_base, tam=45):\n",
    "\n",
    "    files = os.listdir(path_base)\n",
    "    batch_files = np.array_split(files,tam)\n",
    "\n",
    "    return batch_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = \"../../sumdata/dataset_articles\"\n",
    "batch_files = create_batches(path_base, tam=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batches(files, path_base):\n",
    "\n",
    "    disct_list = {}\n",
    "    cont = 1\n",
    "\n",
    "    section_1 = []\n",
    "    section_2 = []\n",
    "    section_3 = []\n",
    "    section_4 = []\n",
    "    keywords = []\n",
    "\n",
    "    texts = loader.load_files(path_base, files)\n",
    "\n",
    "    for i in texts:\n",
    "\n",
    "        #name = files[cont-1].replace(\".json\", \"\")\n",
    "        #disct_list[name] = i\n",
    "\n",
    "        #if cont != save_each == 0:\n",
    "        #    with open('data/{}.json'.format(i), 'w') as f:\n",
    "        #        json.dump(disct_list, f)\n",
    "        #    disct_list = {}\n",
    "        #    cont = 1\n",
    "\n",
    "        section_1.append(preprocess.format_intro(i.get('sec_abstract')))\n",
    "        section_2.append(preprocess.format_intro(i.get('sec_introduction')))\n",
    "        section_3.append(preprocess.format_intro(i.get('sec_materials_and_methods')))\n",
    "        section_4.append(preprocess.format_intro(i.get('sec_results_and_conclusion')))\n",
    "        keywords.append(i.get('sec_keyword'))\n",
    "\n",
    "    return section_1, section_2, section_3, section_4, keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features_batches(batches, path_base, start=0,verbose=True):\n",
    "\n",
    "    all_scores =[ ]\n",
    "    all_features = []\n",
    "    cont = 1\n",
    "\n",
    "    for batch in batches:\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Batch: {} \\n\".format(cont))\n",
    "    \n",
    "        section_1, section_2, section_3, section_4, keywords = load_batches(\n",
    "            batch, path_base)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Iniciando a extração de features...\")\n",
    "            print(\"Total de arquivos: {} \\n\".format(len(section_1)))\n",
    "\n",
    "        for i in range(len(section_1)):\n",
    "            \n",
    "            features_df, scores_df = extract_features_file(\n",
    "                    section=section_2[i], reference=section_1[i], keywords=keywords,\n",
    "                    number_text=i, verbose=True)\n",
    "\n",
    "            if not((features_df.empty) or (scores_df.empty)):\n",
    "\n",
    "                if features_df.shape[0] == scores_df.shape[0]:\n",
    "                    all_scores.append(scores_df)\n",
    "                    all_features.append(features_df)\n",
    "\n",
    "            if (i % 100 == 0) and (i !=0):\n",
    "                print(\"Quantidade de arquivos processados: {}\".format(i))\n",
    "                print(\"Saving Results\")\n",
    "\n",
    "                save_results(all_features, all_scores, number_text=i, verbose=False)\n",
    "                all_scores =[]\n",
    "                all_features = []\n",
    "\n",
    "        cont+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def save_results(all_features, all_scores, number_text, name_section='intro', verbose=False):\n",
    "    \n",
    "    features_df = pd.concat(all_features)\n",
    "    scores_df = pd.concat(all_scores)\n",
    "\n",
    "    features_df.to_csv(\"../result/{}/features_{}.csv\".format(name_section, number_text), index=False)\n",
    "    scores_df.to_csv(\"../result/{}/scores_{}.csv\".format(name_section, number_text), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_file(section, reference, keywords, number_text, verbose=False):\n",
    "  \n",
    "  xml = preprocess.format_xml(str(section))\n",
    "  text = preprocess.format_text(str(section), post_processing=False)\n",
    "  reference = preprocess.format_text(str(reference), post_processing=True)\n",
    "\n",
    "  bibs = extract_features.get_citations(xml)\n",
    "  text = preprocess.replace_bib(text, bibs)\n",
    "  text = preprocess.format_text(text, post_processing=True)\n",
    "\n",
    "  soup = BeautifulSoup(text)\n",
    "  text = soup.get_text()\n",
    "\n",
    "  sentences = tokenizer.split_sentences([text])\n",
    "  sentences = list(map(str, sentences[0]))\n",
    "  sentences = preprocess.format_sentences(sentences)\n",
    "\n",
    "  try: \n",
    "\n",
    "    features = create_features_df.main(\n",
    "      sentences, xml, keywords, number_text, nlp_sm, nlp_md)\n",
    "    features_df = create_features_df.format_df (sentences, features)\n",
    "    features_df['number_text'] = [number_text]*len(features_df)\n",
    "\n",
    "    sentences_ref = tokenizer.split_sentences([reference])\n",
    "    sentences_ref = list(map(str, sentences_ref[0]))\n",
    "\n",
    "    scores_df, label = transform_data.main_create_label(sentences, sentences_ref, rouge)\n",
    "    scores_df['label'] = label\n",
    "    scores_df['number_text'] = [number_text]*len(scores_df)\n",
    "\n",
    "    return features_df, scores_df\n",
    "\n",
    "  except ValueError as error:\n",
    "    return pd.DataFrame(), pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1 \n",
      "\n",
      "Iniciando a extração de features...\n",
      "Total de arquivos: 1054 \n",
      "\n",
      "Quantidade de arquivos processados: 0\n",
      "Saving Results\n",
      "Quantidade de arquivos processados: 100\n",
      "Saving Results\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-55934ca874c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../../sumdata/dataset_articles\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mextract_features_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-aaf240c85936>\u001b[0m in \u001b[0;36mextract_features_batches\u001b[0;34m(batches, path_base, start, verbose)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             features_df, scores_df = extract_features_file(\n\u001b[0m\u001b[1;32m     22\u001b[0m                     \u001b[0msection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msection_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msection_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     number_text=i, verbose=True)\n",
      "\u001b[0;32m<ipython-input-7-c8549f9386a2>\u001b[0m in \u001b[0;36mextract_features_file\u001b[0;34m(section, reference, keywords, number_text, verbose)\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     features = create_features_df.main(\n\u001b[0m\u001b[1;32m     21\u001b[0m       sentences, xml, keywords, number_text, nlp_sm, nlp_md)\n\u001b[1;32m     22\u001b[0m     \u001b[0mfeatures_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_features_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_df\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/cinthia/Dados/Mestrado/mv-text-summarizer/src/create_features_df.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(text, xml, article_keywords, number_text, nlp_sm, nlp_md)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0;31m#POS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m   \u001b[0mcount_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp_sm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m   \u001b[0mcount_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcount_tag\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m   \u001b[0mpos_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_tag\u001b[0m \u001b[0;31m#calc_score(count_tag, metric='max')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/cinthia/Dados/Mestrado/mv-text-summarizer/src/extract_features.py\u001b[0m in \u001b[0;36mpostag\u001b[0;34m(section, nlp)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"NOUN\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"VERB\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ADJ\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ADV\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mcount_aux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mv-summarization/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__call__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.predict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.greedy_parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mv-summarization/lib/python3.8/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mv-summarization/lib/python3.8/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserModel.begin_update\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserStepModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mv-summarization/lib/python3.8/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mv-summarization/lib/python3.8/site-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(seqs_in, drop)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mv-summarization/lib/python3.8/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mv-summarization/lib/python3.8/site-packages/thinc/neural/_classes/resnet.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mv-summarization/lib/python3.8/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mv-summarization/lib/python3.8/site-packages/thinc/neural/_classes/layernorm.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mbackprop_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_moments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mXhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mv-summarization/lib/python3.8/site-packages/thinc/neural/_classes/layernorm.py\u001b[0m in \u001b[0;36m_get_moments\u001b[0;34m(ops, X)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_moments_reproduce_bug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-08\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"f\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mv-summarization/lib/python3.8/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mrcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mv-summarization/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mset_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'numpy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \"\"\"Convert the input to an ndarray, but pass ndarray subclasses through.\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path_base = \"../../sumdata/dataset_articles\"\n",
    "\n",
    "extract_features_batches(batch_files[:1], path_base, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = loader.read_features(path=\"../result/features_*.csv\")\n",
    "scores_df = loader.read_features(path=\"../result/scores_*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(20947, 15)\n(20947, 4)\n"
     ]
    }
   ],
   "source": [
    "print(features_df.shape)\n",
    "print(scores_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = features_df.columns\n",
    "X = features_df[columns_name[1:]]\n",
    "y = scores_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " X = normalization.standart_norm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = classifiers.data_classification(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4710, 14)\n(6285, 14)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "source": [
    "# Random Forest Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfsearch = th.get_hiperparametrs_rf(X_train, y_train, parameters=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = classifiers.fit_rf(X_train, y_train, rfsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.925513  0.770237  0.840766  5275.000000\n",
       "1              0.360422  0.676238  0.470224  1010.000000\n",
       "accuracy       0.755131  0.755131  0.755131     0.755131\n",
       "macro avg      0.642967  0.723237  0.655495  6285.000000\n",
       "weighted avg   0.834702  0.755131  0.781220  6285.000000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.925513</td>\n      <td>0.770237</td>\n      <td>0.840766</td>\n      <td>5275.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.360422</td>\n      <td>0.676238</td>\n      <td>0.470224</td>\n      <td>1010.000000</td>\n    </tr>\n    <tr>\n      <th>accuracy</th>\n      <td>0.755131</td>\n      <td>0.755131</td>\n      <td>0.755131</td>\n      <td>0.755131</td>\n    </tr>\n    <tr>\n      <th>macro avg</th>\n      <td>0.642967</td>\n      <td>0.723237</td>\n      <td>0.655495</td>\n      <td>6285.000000</td>\n    </tr>\n    <tr>\n      <th>weighted avg</th>\n      <td>0.834702</td>\n      <td>0.755131</td>\n      <td>0.781220</td>\n      <td>6285.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "scores, y_pred = classifiers.evaluate_model(X_test, y_test, rf)\n",
    "scores"
   ]
  },
  {
   "source": [
    "# Neural Model Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import neural_model\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "y: 0.8577 - val_precision: 0.6667 - val_recall: 0.0084 - val_auc: 0.7081 - val_prc: 0.2981\n",
      "Epoch 47/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3249 - tp: 318.1692 - fp: 19.5614 - tn: 5596.2229 - fn: 786.0226 - accuracy: 0.8816 - precision: 0.9396 - recall: 0.2942 - auc: 0.8124 - prc: 0.5916 - val_loss: 0.3776 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 475.0000 - val_accuracy: 0.8577 - val_precision: 0.6667 - val_recall: 0.0084 - val_auc: 0.7075 - val_prc: 0.2967\n",
      "Epoch 48/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3286 - tp: 330.4231 - fp: 24.1323 - tn: 5588.4899 - fn: 776.9309 - accuracy: 0.8813 - precision: 0.9264 - recall: 0.3034 - auc: 0.8103 - prc: 0.5962 - val_loss: 0.3770 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 475.0000 - val_accuracy: 0.8577 - val_precision: 0.6667 - val_recall: 0.0084 - val_auc: 0.7117 - val_prc: 0.2993\n",
      "Epoch 49/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3223 - tp: 323.9809 - fp: 23.9631 - tn: 5603.0167 - fn: 769.0155 - accuracy: 0.8827 - precision: 0.9311 - recall: 0.3017 - auc: 0.8146 - prc: 0.5985 - val_loss: 0.3795 - val_tp: 5.0000 - val_fp: 5.0000 - val_tn: 2868.0000 - val_fn: 474.0000 - val_accuracy: 0.8571 - val_precision: 0.5000 - val_recall: 0.0104 - val_auc: 0.7107 - val_prc: 0.2957\n",
      "Epoch 50/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3302 - tp: 329.7259 - fp: 22.5959 - tn: 5591.6961 - fn: 775.9583 - accuracy: 0.8795 - precision: 0.9333 - recall: 0.2987 - auc: 0.8118 - prc: 0.5932 - val_loss: 0.3775 - val_tp: 5.0000 - val_fp: 4.0000 - val_tn: 2869.0000 - val_fn: 474.0000 - val_accuracy: 0.8574 - val_precision: 0.5556 - val_recall: 0.0104 - val_auc: 0.7106 - val_prc: 0.3006\n",
      "Epoch 51/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3135 - tp: 330.9106 - fp: 26.8999 - tn: 5598.1764 - fn: 763.9893 - accuracy: 0.8875 - precision: 0.9280 - recall: 0.3156 - auc: 0.8199 - prc: 0.6058 - val_loss: 0.3770 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 476.0000 - val_accuracy: 0.8574 - val_precision: 0.6000 - val_recall: 0.0063 - val_auc: 0.7121 - val_prc: 0.3013\n",
      "Epoch 52/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3210 - tp: 320.1573 - fp: 15.7378 - tn: 5597.3361 - fn: 786.7449 - accuracy: 0.8820 - precision: 0.9517 - recall: 0.2939 - auc: 0.8162 - prc: 0.6019 - val_loss: 0.3766 - val_tp: 4.0000 - val_fp: 3.0000 - val_tn: 2870.0000 - val_fn: 475.0000 - val_accuracy: 0.8574 - val_precision: 0.5714 - val_recall: 0.0084 - val_auc: 0.7101 - val_prc: 0.2994\n",
      "Epoch 53/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3237 - tp: 320.6508 - fp: 18.2122 - tn: 5601.9821 - fn: 779.1311 - accuracy: 0.8842 - precision: 0.9474 - recall: 0.3048 - auc: 0.8105 - prc: 0.5969 - val_loss: 0.3757 - val_tp: 5.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 474.0000 - val_accuracy: 0.8580 - val_precision: 0.7143 - val_recall: 0.0104 - val_auc: 0.7112 - val_prc: 0.3054\n",
      "Epoch 54/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3183 - tp: 346.6174 - fp: 32.1979 - tn: 5564.7342 - fn: 776.4267 - accuracy: 0.8821 - precision: 0.9145 - recall: 0.3225 - auc: 0.8251 - prc: 0.6238 - val_loss: 0.3785 - val_tp: 5.0000 - val_fp: 4.0000 - val_tn: 2869.0000 - val_fn: 474.0000 - val_accuracy: 0.8574 - val_precision: 0.5556 - val_recall: 0.0104 - val_auc: 0.7098 - val_prc: 0.2966\n",
      "Epoch 55/100\n",
      "838/838 [==============================] - 2s 3ms/step - loss: 0.3217 - tp: 332.0918 - fp: 24.0763 - tn: 5589.9523 - fn: 773.8558 - accuracy: 0.8808 - precision: 0.9291 - recall: 0.2968 - auc: 0.8182 - prc: 0.6071 - val_loss: 0.3792 - val_tp: 5.0000 - val_fp: 3.0000 - val_tn: 2870.0000 - val_fn: 474.0000 - val_accuracy: 0.8577 - val_precision: 0.6250 - val_recall: 0.0104 - val_auc: 0.7082 - val_prc: 0.2967\n",
      "Epoch 56/100\n",
      "838/838 [==============================] - 2s 3ms/step - loss: 0.3278 - tp: 335.2539 - fp: 26.1692 - tn: 5578.8701 - fn: 779.6830 - accuracy: 0.8790 - precision: 0.9234 - recall: 0.2995 - auc: 0.8131 - prc: 0.5998 - val_loss: 0.3786 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 475.0000 - val_accuracy: 0.8577 - val_precision: 0.6667 - val_recall: 0.0084 - val_auc: 0.7082 - val_prc: 0.2989\n",
      "Epoch 57/100\n",
      "838/838 [==============================] - 3s 4ms/step - loss: 0.3239 - tp: 340.9392 - fp: 29.4827 - tn: 5589.8308 - fn: 759.7235 - accuracy: 0.8804 - precision: 0.9244 - recall: 0.3125 - auc: 0.8156 - prc: 0.6126 - val_loss: 0.3775 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 2870.0000 - val_fn: 476.0000 - val_accuracy: 0.8571 - val_precision: 0.5000 - val_recall: 0.0063 - val_auc: 0.7076 - val_prc: 0.2967\n",
      "Epoch 58/100\n",
      "838/838 [==============================] - 3s 4ms/step - loss: 0.3247 - tp: 328.8403 - fp: 23.2634 - tn: 5612.2813 - fn: 755.5912 - accuracy: 0.8848 - precision: 0.9371 - recall: 0.3062 - auc: 0.8049 - prc: 0.5917 - val_loss: 0.3783 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 475.0000 - val_accuracy: 0.8577 - val_precision: 0.6667 - val_recall: 0.0084 - val_auc: 0.7085 - val_prc: 0.3014\n",
      "Epoch 59/100\n",
      "838/838 [==============================] - 3s 4ms/step - loss: 0.3257 - tp: 331.3290 - fp: 23.7330 - tn: 5578.7867 - fn: 786.1275 - accuracy: 0.8792 - precision: 0.9293 - recall: 0.2918 - auc: 0.8173 - prc: 0.5997 - val_loss: 0.3780 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 2870.0000 - val_fn: 476.0000 - val_accuracy: 0.8571 - val_precision: 0.5000 - val_recall: 0.0063 - val_auc: 0.7072 - val_prc: 0.2990\n",
      "Epoch 60/100\n",
      "838/838 [==============================] - 2s 3ms/step - loss: 0.3257 - tp: 318.9845 - fp: 27.2729 - tn: 5575.8963 - fn: 797.8224 - accuracy: 0.8766 - precision: 0.9126 - recall: 0.2847 - auc: 0.8181 - prc: 0.6026 - val_loss: 0.3790 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 2869.0000 - val_fn: 476.0000 - val_accuracy: 0.8568 - val_precision: 0.4286 - val_recall: 0.0063 - val_auc: 0.7087 - val_prc: 0.3012\n",
      "Epoch 61/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3151 - tp: 342.1251 - fp: 32.9452 - tn: 5576.7557 - fn: 768.1502 - accuracy: 0.8821 - precision: 0.9095 - recall: 0.3141 - auc: 0.8247 - prc: 0.6236 - val_loss: 0.3790 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 2869.0000 - val_fn: 475.0000 - val_accuracy: 0.8571 - val_precision: 0.5000 - val_recall: 0.0084 - val_auc: 0.7097 - val_prc: 0.3024\n",
      "Epoch 62/100\n",
      "838/838 [==============================] - 2s 3ms/step - loss: 0.3307 - tp: 329.9476 - fp: 24.1657 - tn: 5570.9666 - fn: 794.8963 - accuracy: 0.8767 - precision: 0.9343 - recall: 0.2946 - auc: 0.8143 - prc: 0.6019 - val_loss: 0.3772 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 476.0000 - val_accuracy: 0.8574 - val_precision: 0.6000 - val_recall: 0.0063 - val_auc: 0.7095 - val_prc: 0.3010\n",
      "Epoch 63/100\n",
      "838/838 [==============================] - 2s 3ms/step - loss: 0.3211 - tp: 332.7128 - fp: 18.8844 - tn: 5588.1788 - fn: 780.2002 - accuracy: 0.8824 - precision: 0.9533 - recall: 0.3012 - auc: 0.8193 - prc: 0.6089 - val_loss: 0.3774 - val_tp: 3.0000 - val_fp: 5.0000 - val_tn: 2868.0000 - val_fn: 476.0000 - val_accuracy: 0.8565 - val_precision: 0.3750 - val_recall: 0.0063 - val_auc: 0.7089 - val_prc: 0.3005\n",
      "Epoch 64/100\n",
      "838/838 [==============================] - 2s 2ms/step - loss: 0.3211 - tp: 332.6114 - fp: 24.4791 - tn: 5582.2181 - fn: 780.6675 - accuracy: 0.8800 - precision: 0.9331 - recall: 0.2943 - auc: 0.8213 - prc: 0.6070 - val_loss: 0.3779 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 476.0000 - val_accuracy: 0.8574 - val_precision: 0.6000 - val_recall: 0.0063 - val_auc: 0.7106 - val_prc: 0.3012\n",
      "Epoch 65/100\n",
      "838/838 [==============================] - 2s 3ms/step - loss: 0.3200 - tp: 328.4303 - fp: 21.9762 - tn: 5594.3135 - fn: 775.2563 - accuracy: 0.8827 - precision: 0.9374 - recall: 0.2978 - auc: 0.8137 - prc: 0.6004 - val_loss: 0.3773 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 475.0000 - val_accuracy: 0.8577 - val_precision: 0.6667 - val_recall: 0.0084 - val_auc: 0.7105 - val_prc: 0.3038\n",
      "Epoch 66/100\n",
      "838/838 [==============================] - 5s 6ms/step - loss: 0.3216 - tp: 320.1788 - fp: 17.2372 - tn: 5605.1120 - fn: 777.4482 - accuracy: 0.8807 - precision: 0.9496 - recall: 0.2837 - auc: 0.8131 - prc: 0.5933 - val_loss: 0.3789 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 476.0000 - val_accuracy: 0.8574 - val_precision: 0.6000 - val_recall: 0.0063 - val_auc: 0.7073 - val_prc: 0.3024\n",
      "Epoch 67/100\n",
      "838/838 [==============================] - 2s 3ms/step - loss: 0.3283 - tp: 327.6365 - fp: 21.8605 - tn: 5580.1216 - fn: 790.3576 - accuracy: 0.8786 - precision: 0.9281 - recall: 0.2942 - auc: 0.8062 - prc: 0.5969 - val_loss: 0.3764 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 476.0000 - val_accuracy: 0.8574 - val_precision: 0.6000 - val_recall: 0.0063 - val_auc: 0.7118 - val_prc: 0.3079\n",
      "Epoch 68/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3223 - tp: 338.9738 - fp: 21.7592 - tn: 5580.3826 - fn: 778.8605 - accuracy: 0.8822 - precision: 0.9361 - recall: 0.3160 - auc: 0.8168 - prc: 0.6155 - val_loss: 0.3760 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 476.0000 - val_accuracy: 0.8574 - val_precision: 0.6000 - val_recall: 0.0063 - val_auc: 0.7115 - val_prc: 0.3061\n",
      "Epoch 69/100\n",
      "838/838 [==============================] - 3s 4ms/step - loss: 0.3266 - tp: 337.8963 - fp: 25.2598 - tn: 5567.4327 - fn: 789.3874 - accuracy: 0.8783 - precision: 0.9286 - recall: 0.2991 - auc: 0.8225 - prc: 0.6176 - val_loss: 0.3779 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 478.0000 - val_accuracy: 0.8568 - val_precision: 0.3333 - val_recall: 0.0021 - val_auc: 0.7090 - val_prc: 0.3041\n",
      "Epoch 70/100\n",
      "838/838 [==============================] - 3s 4ms/step - loss: 0.3244 - tp: 340.5077 - fp: 17.2598 - tn: 5573.6901 - fn: 788.5185 - accuracy: 0.8787 - precision: 0.9459 - recall: 0.3053 - auc: 0.8189 - prc: 0.6207 - val_loss: 0.3777 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 476.0000 - val_accuracy: 0.8574 - val_precision: 0.6000 - val_recall: 0.0063 - val_auc: 0.7089 - val_prc: 0.3009\n",
      "Epoch 71/100\n",
      "838/838 [==============================] - 3s 4ms/step - loss: 0.3210 - tp: 323.4052 - fp: 25.5614 - tn: 5577.8808 - fn: 793.1287 - accuracy: 0.8786 - precision: 0.9167 - recall: 0.2856 - auc: 0.8214 - prc: 0.5999 - val_loss: 0.3775 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 476.0000 - val_accuracy: 0.8574 - val_precision: 0.6000 - val_recall: 0.0063 - val_auc: 0.7093 - val_prc: 0.2973\n",
      "Epoch 72/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3180 - tp: 329.7473 - fp: 16.6305 - tn: 5594.4625 - fn: 779.1359 - accuracy: 0.8836 - precision: 0.9483 - recall: 0.2969 - auc: 0.8225 - prc: 0.6026 - val_loss: 0.3786 - val_tp: 4.0000 - val_fp: 3.0000 - val_tn: 2870.0000 - val_fn: 475.0000 - val_accuracy: 0.8574 - val_precision: 0.5714 - val_recall: 0.0084 - val_auc: 0.7081 - val_prc: 0.3003\n",
      "Epoch 73/100\n",
      "838/838 [==============================] - 3s 4ms/step - loss: 0.3175 - tp: 320.4160 - fp: 16.5077 - tn: 5612.8629 - fn: 770.1895 - accuracy: 0.8828 - precision: 0.9452 - recall: 0.2983 - auc: 0.8220 - prc: 0.6084 - val_loss: 0.3769 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 2869.0000 - val_fn: 475.0000 - val_accuracy: 0.8571 - val_precision: 0.5000 - val_recall: 0.0084 - val_auc: 0.7104 - val_prc: 0.2981\n",
      "Epoch 74/100\n",
      "838/838 [==============================] - 3s 4ms/step - loss: 0.3176 - tp: 334.1633 - fp: 21.9762 - tn: 5590.2098 - fn: 773.6269 - accuracy: 0.8821 - precision: 0.9441 - recall: 0.3112 - auc: 0.8280 - prc: 0.6231 - val_loss: 0.3761 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 477.0000 - val_accuracy: 0.8571 - val_precision: 0.5000 - val_recall: 0.0042 - val_auc: 0.7107 - val_prc: 0.2980\n",
      "Epoch 75/100\n",
      "838/838 [==============================] - 3s 4ms/step - loss: 0.3275 - tp: 318.6353 - fp: 17.8284 - tn: 5606.2551 - fn: 777.2574 - accuracy: 0.8815 - precision: 0.9422 - recall: 0.2841 - auc: 0.8081 - prc: 0.5802 - val_loss: 0.3766 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 476.0000 - val_accuracy: 0.8574 - val_precision: 0.6000 - val_recall: 0.0063 - val_auc: 0.7095 - val_prc: 0.2993\n",
      "Epoch 76/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3141 - tp: 324.3385 - fp: 17.8558 - tn: 5599.6818 - fn: 778.1001 - accuracy: 0.8830 - precision: 0.9485 - recall: 0.2955 - auc: 0.8209 - prc: 0.6112 - val_loss: 0.3775 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 476.0000 - val_accuracy: 0.8574 - val_precision: 0.6000 - val_recall: 0.0063 - val_auc: 0.7110 - val_prc: 0.3031\n",
      "Epoch 77/100\n",
      "838/838 [==============================] - 3s 4ms/step - loss: 0.3261 - tp: 327.0310 - fp: 22.8582 - tn: 5581.4923 - fn: 788.5948 - accuracy: 0.8795 - precision: 0.9223 - recall: 0.2854 - auc: 0.8100 - prc: 0.5978 - val_loss: 0.3764 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 476.0000 - val_accuracy: 0.8574 - val_precision: 0.6000 - val_recall: 0.0063 - val_auc: 0.7113 - val_prc: 0.3027\n",
      "Epoch 78/100\n",
      "838/838 [==============================] - 3s 4ms/step - loss: 0.3179 - tp: 311.2908 - fp: 17.5793 - tn: 5620.2658 - fn: 770.8403 - accuracy: 0.8844 - precision: 0.9553 - recall: 0.2886 - auc: 0.8114 - prc: 0.5940 - val_loss: 0.3791 - val_tp: 5.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 474.0000 - val_accuracy: 0.8580 - val_precision: 0.7143 - val_recall: 0.0104 - val_auc: 0.7064 - val_prc: 0.2997\n",
      "Epoch 79/100\n",
      "838/838 [==============================] - 3s 4ms/step - loss: 0.3224 - tp: 321.4958 - fp: 23.8498 - tn: 5600.0441 - fn: 774.5864 - accuracy: 0.8793 - precision: 0.9250 - recall: 0.2883 - auc: 0.8171 - prc: 0.6028 - val_loss: 0.3772 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 2870.0000 - val_fn: 476.0000 - val_accuracy: 0.8571 - val_precision: 0.5000 - val_recall: 0.0063 - val_auc: 0.7093 - val_prc: 0.2992\n",
      "Epoch 80/100\n",
      "838/838 [==============================] - 2s 3ms/step - loss: 0.3232 - tp: 319.9237 - fp: 21.9225 - tn: 5593.2026 - fn: 784.9273 - accuracy: 0.8789 - precision: 0.9331 - recall: 0.2863 - auc: 0.8151 - prc: 0.5971 - val_loss: 0.3788 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 476.0000 - val_accuracy: 0.8574 - val_precision: 0.6000 - val_recall: 0.0063 - val_auc: 0.7097 - val_prc: 0.2999\n",
      "Epoch 81/100\n",
      "838/838 [==============================] - 2s 2ms/step - loss: 0.3236 - tp: 317.3385 - fp: 17.5197 - tn: 5589.5566 - fn: 795.5614 - accuracy: 0.8791 - precision: 0.9417 - recall: 0.2843 - auc: 0.8132 - prc: 0.6004 - val_loss: 0.3784 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 475.0000 - val_accuracy: 0.8577 - val_precision: 0.6667 - val_recall: 0.0084 - val_auc: 0.7104 - val_prc: 0.3013\n",
      "Epoch 82/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3246 - tp: 338.8081 - fp: 24.9094 - tn: 5579.6448 - fn: 776.6138 - accuracy: 0.8791 - precision: 0.9278 - recall: 0.2998 - auc: 0.8217 - prc: 0.6207 - val_loss: 0.3791 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 476.0000 - val_accuracy: 0.8574 - val_precision: 0.6000 - val_recall: 0.0063 - val_auc: 0.7094 - val_prc: 0.3012\n",
      "Epoch 83/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3189 - tp: 337.9213 - fp: 16.6675 - tn: 5578.8880 - fn: 786.4994 - accuracy: 0.8818 - precision: 0.9546 - recall: 0.2964 - auc: 0.8205 - prc: 0.6067 - val_loss: 0.3773 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 476.0000 - val_accuracy: 0.8574 - val_precision: 0.6000 - val_recall: 0.0063 - val_auc: 0.7100 - val_prc: 0.3000\n",
      "Epoch 84/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3174 - tp: 332.8820 - fp: 23.5840 - tn: 5595.5959 - fn: 767.9142 - accuracy: 0.8831 - precision: 0.9352 - recall: 0.3089 - auc: 0.8186 - prc: 0.6142 - val_loss: 0.3792 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 2870.0000 - val_fn: 476.0000 - val_accuracy: 0.8571 - val_precision: 0.5000 - val_recall: 0.0063 - val_auc: 0.7077 - val_prc: 0.2935\n",
      "Epoch 85/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3269 - tp: 337.5185 - fp: 23.4934 - tn: 5583.2396 - fn: 775.7247 - accuracy: 0.8775 - precision: 0.9302 - recall: 0.2932 - auc: 0.8141 - prc: 0.6081 - val_loss: 0.3795 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 2870.0000 - val_fn: 477.0000 - val_accuracy: 0.8568 - val_precision: 0.4000 - val_recall: 0.0042 - val_auc: 0.7086 - val_prc: 0.2970\n",
      "Epoch 86/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3279 - tp: 315.0620 - fp: 20.2563 - tn: 5592.4553 - fn: 792.2026 - accuracy: 0.8792 - precision: 0.9434 - recall: 0.2838 - auc: 0.8083 - prc: 0.5891 - val_loss: 0.3776 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 476.0000 - val_accuracy: 0.8574 - val_precision: 0.6000 - val_recall: 0.0063 - val_auc: 0.7115 - val_prc: 0.2981\n",
      "Epoch 87/100\n",
      "838/838 [==============================] - 2s 2ms/step - loss: 0.3267 - tp: 334.0822 - fp: 33.0989 - tn: 5576.0870 - fn: 776.7080 - accuracy: 0.8800 - precision: 0.9069 - recall: 0.3041 - auc: 0.8083 - prc: 0.5965 - val_loss: 0.3766 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 476.0000 - val_accuracy: 0.8574 - val_precision: 0.6000 - val_recall: 0.0063 - val_auc: 0.7087 - val_prc: 0.3008\n",
      "Epoch 88/100\n",
      "838/838 [==============================] - 2s 2ms/step - loss: 0.3231 - tp: 340.3170 - fp: 23.5209 - tn: 5584.1681 - fn: 771.9702 - accuracy: 0.8823 - precision: 0.9319 - recall: 0.3063 - auc: 0.8136 - prc: 0.6015 - val_loss: 0.3780 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 476.0000 - val_accuracy: 0.8574 - val_precision: 0.6000 - val_recall: 0.0063 - val_auc: 0.7100 - val_prc: 0.2974\n",
      "Epoch 89/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3236 - tp: 335.5483 - fp: 24.6818 - tn: 5588.9845 - fn: 770.7616 - accuracy: 0.8795 - precision: 0.9227 - recall: 0.3021 - auc: 0.8179 - prc: 0.6056 - val_loss: 0.3773 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 475.0000 - val_accuracy: 0.8577 - val_precision: 0.6667 - val_recall: 0.0084 - val_auc: 0.7110 - val_prc: 0.3017\n",
      "Epoch 90/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3113 - tp: 338.8474 - fp: 24.6150 - tn: 5591.2443 - fn: 765.2694 - accuracy: 0.8849 - precision: 0.9369 - recall: 0.3166 - auc: 0.8261 - prc: 0.6240 - val_loss: 0.3769 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 475.0000 - val_accuracy: 0.8577 - val_precision: 0.6667 - val_recall: 0.0084 - val_auc: 0.7124 - val_prc: 0.3019\n",
      "Epoch 91/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3285 - tp: 327.0608 - fp: 18.5375 - tn: 5593.2849 - fn: 781.0930 - accuracy: 0.8808 - precision: 0.9470 - recall: 0.2953 - auc: 0.8051 - prc: 0.5918 - val_loss: 0.3773 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 476.0000 - val_accuracy: 0.8574 - val_precision: 0.6000 - val_recall: 0.0063 - val_auc: 0.7100 - val_prc: 0.3009\n",
      "Epoch 92/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3178 - tp: 330.4875 - fp: 23.1013 - tn: 5582.2241 - fn: 784.1633 - accuracy: 0.8818 - precision: 0.9374 - recall: 0.3036 - auc: 0.8170 - prc: 0.6105 - val_loss: 0.3781 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 477.0000 - val_accuracy: 0.8571 - val_precision: 0.5000 - val_recall: 0.0042 - val_auc: 0.7099 - val_prc: 0.2997\n",
      "Epoch 93/100\n",
      "838/838 [==============================] - 3s 3ms/step - loss: 0.3144 - tp: 332.7366 - fp: 20.6400 - tn: 5596.4720 - fn: 770.1275 - accuracy: 0.8846 - precision: 0.9433 - recall: 0.3134 - auc: 0.8224 - prc: 0.6227 - val_loss: 0.3757 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 2871.0000 - val_fn: 477.0000 - val_accuracy: 0.8571 - val_precision: 0.5000 - val_recall: 0.0042 - val_auc: 0.7106 - val_prc: 0.2980\n",
      "Epoch 00093: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "kFold = StratifiedKFold(n_splits=5)\n",
    "scores =[]\n",
    "for train, test in kFold.split(X, y):\n",
    "\n",
    "    model = neural_model.simple_nn(METRICS)\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=40)\n",
    "    model.fit(X[train], y[train], epochs=100, batch_size=16, validation_split=0.2, callbacks=[es])\n",
    "    scores.append(model.evaluate(X[test], y[test], verbose=0))\n",
    "\n",
    "    history.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5425 - tp: 320.5190 - fp: 135.0802 - tn: 1055.7173 - fn: 392.5485 - accuracy: 0.7256 - precision: 0.7049 - recall: 0.4512 - auc: 0.7705 - prc: 0.6953 - val_loss: 0.7812 - val_tp: 444.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 498.0000 - val_accuracy: 0.4713 - val_precision: 1.0000 - val_recall: 0.4713 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 56/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 0.5596 - tp: 321.6203 - fp: 133.6076 - tn: 1053.9241 - fn: 394.7131 - accuracy: 0.7182 - precision: 0.6989 - recall: 0.4377 - auc: 0.7548 - prc: 0.6757 - val_loss: 0.7541 - val_tp: 454.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 488.0000 - val_accuracy: 0.4820 - val_precision: 1.0000 - val_recall: 0.4820 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 57/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 0.5463 - tp: 347.8397 - fp: 137.9662 - tn: 1040.3797 - fn: 377.6793 - accuracy: 0.7325 - precision: 0.7169 - recall: 0.4887 - auc: 0.7694 - prc: 0.7018 - val_loss: 0.8100 - val_tp: 414.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 528.0000 - val_accuracy: 0.4395 - val_precision: 1.0000 - val_recall: 0.4395 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 58/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5618 - tp: 303.0591 - fp: 117.6793 - tn: 1087.7257 - fn: 395.4008 - accuracy: 0.7293 - precision: 0.7238 - recall: 0.4383 - auc: 0.7545 - prc: 0.6747 - val_loss: 0.7456 - val_tp: 471.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 471.0000 - val_accuracy: 0.5000 - val_precision: 1.0000 - val_recall: 0.5000 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 59/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5455 - tp: 324.4684 - fp: 145.3207 - tn: 1060.6835 - fn: 373.3924 - accuracy: 0.7264 - precision: 0.6770 - recall: 0.4738 - auc: 0.7636 - prc: 0.6728 - val_loss: 0.7714 - val_tp: 444.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 498.0000 - val_accuracy: 0.4713 - val_precision: 1.0000 - val_recall: 0.4713 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 60/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 0.5427 - tp: 319.6076 - fp: 123.3840 - tn: 1070.5823 - fn: 390.2911 - accuracy: 0.7294 - precision: 0.7193 - recall: 0.4448 - auc: 0.7733 - prc: 0.6906 - val_loss: 0.7679 - val_tp: 438.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 504.0000 - val_accuracy: 0.4650 - val_precision: 1.0000 - val_recall: 0.4650 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 61/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 0.5568 - tp: 341.8059 - fp: 142.0591 - tn: 1036.2025 - fn: 383.7975 - accuracy: 0.7216 - precision: 0.7121 - recall: 0.4618 - auc: 0.7561 - prc: 0.6856 - val_loss: 0.8098 - val_tp: 411.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 531.0000 - val_accuracy: 0.4363 - val_precision: 1.0000 - val_recall: 0.4363 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 62/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5166 - tp: 311.0802 - fp: 112.2068 - tn: 1094.2827 - fn: 386.2954 - accuracy: 0.7511 - precision: 0.7532 - recall: 0.4578 - auc: 0.7854 - prc: 0.7163 - val_loss: 0.7915 - val_tp: 418.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 524.0000 - val_accuracy: 0.4437 - val_precision: 1.0000 - val_recall: 0.4437 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 63/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5334 - tp: 328.9536 - fp: 121.8143 - tn: 1065.5021 - fn: 387.5949 - accuracy: 0.7345 - precision: 0.7365 - recall: 0.4666 - auc: 0.7845 - prc: 0.7136 - val_loss: 0.7602 - val_tp: 427.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 515.0000 - val_accuracy: 0.4533 - val_precision: 1.0000 - val_recall: 0.4533 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 64/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 0.5367 - tp: 323.2025 - fp: 127.6751 - tn: 1073.1181 - fn: 379.8692 - accuracy: 0.7336 - precision: 0.7133 - recall: 0.4581 - auc: 0.7703 - prc: 0.6962 - val_loss: 0.7804 - val_tp: 417.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 525.0000 - val_accuracy: 0.4427 - val_precision: 1.0000 - val_recall: 0.4427 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 65/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 0.5401 - tp: 313.6371 - fp: 121.9030 - tn: 1067.8861 - fn: 400.4388 - accuracy: 0.7251 - precision: 0.7026 - recall: 0.4301 - auc: 0.7680 - prc: 0.6872 - val_loss: 0.8170 - val_tp: 402.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 540.0000 - val_accuracy: 0.4268 - val_precision: 1.0000 - val_recall: 0.4268 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 66/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 0.5463 - tp: 321.7932 - fp: 126.9367 - tn: 1066.7848 - fn: 388.3502 - accuracy: 0.7268 - precision: 0.7073 - recall: 0.4478 - auc: 0.7631 - prc: 0.6847 - val_loss: 0.7806 - val_tp: 434.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 508.0000 - val_accuracy: 0.4607 - val_precision: 1.0000 - val_recall: 0.4607 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 67/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5193 - tp: 328.2785 - fp: 132.0253 - tn: 1073.5232 - fn: 370.0380 - accuracy: 0.7476 - precision: 0.7258 - recall: 0.4923 - auc: 0.7939 - prc: 0.7151 - val_loss: 0.7705 - val_tp: 427.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 515.0000 - val_accuracy: 0.4533 - val_precision: 1.0000 - val_recall: 0.4533 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 68/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 0.5395 - tp: 320.4937 - fp: 131.6498 - tn: 1063.4430 - fn: 388.2785 - accuracy: 0.7279 - precision: 0.7166 - recall: 0.4521 - auc: 0.7830 - prc: 0.6935 - val_loss: 0.7767 - val_tp: 436.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 506.0000 - val_accuracy: 0.4628 - val_precision: 1.0000 - val_recall: 0.4628 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 69/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 0.5391 - tp: 334.4219 - fp: 129.7511 - tn: 1062.7511 - fn: 376.9409 - accuracy: 0.7369 - precision: 0.7285 - recall: 0.4752 - auc: 0.7710 - prc: 0.7097 - val_loss: 0.7784 - val_tp: 439.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 503.0000 - val_accuracy: 0.4660 - val_precision: 1.0000 - val_recall: 0.4660 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 70/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5564 - tp: 319.7595 - fp: 134.1730 - tn: 1065.6371 - fn: 384.2954 - accuracy: 0.7303 - precision: 0.6980 - recall: 0.4558 - auc: 0.7612 - prc: 0.6763 - val_loss: 0.7872 - val_tp: 423.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 519.0000 - val_accuracy: 0.4490 - val_precision: 1.0000 - val_recall: 0.4490 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 71/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5407 - tp: 334.7004 - fp: 119.9325 - tn: 1066.8186 - fn: 382.4135 - accuracy: 0.7401 - precision: 0.7450 - recall: 0.4723 - auc: 0.7752 - prc: 0.7124 - val_loss: 0.7734 - val_tp: 447.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 495.0000 - val_accuracy: 0.4745 - val_precision: 1.0000 - val_recall: 0.4745 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 72/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5242 - tp: 344.7004 - fp: 139.0928 - tn: 1054.2489 - fn: 365.8228 - accuracy: 0.7366 - precision: 0.7072 - recall: 0.4952 - auc: 0.7902 - prc: 0.7155 - val_loss: 0.7682 - val_tp: 440.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 502.0000 - val_accuracy: 0.4671 - val_precision: 1.0000 - val_recall: 0.4671 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 73/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5375 - tp: 346.9030 - fp: 136.5781 - tn: 1040.9831 - fn: 379.4008 - accuracy: 0.7297 - precision: 0.7179 - recall: 0.4823 - auc: 0.7798 - prc: 0.7134 - val_loss: 0.8253 - val_tp: 392.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 550.0000 - val_accuracy: 0.4161 - val_precision: 1.0000 - val_recall: 0.4161 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 74/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5544 - tp: 312.8059 - fp: 129.7046 - tn: 1066.3122 - fn: 395.0422 - accuracy: 0.7219 - precision: 0.7053 - recall: 0.4347 - auc: 0.7677 - prc: 0.6846 - val_loss: 0.7631 - val_tp: 439.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 503.0000 - val_accuracy: 0.4660 - val_precision: 1.0000 - val_recall: 0.4660 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 75/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 0.5461 - tp: 321.0844 - fp: 126.8101 - tn: 1068.8270 - fn: 387.1435 - accuracy: 0.7282 - precision: 0.7208 - recall: 0.4544 - auc: 0.7720 - prc: 0.6999 - val_loss: 0.7648 - val_tp: 455.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 487.0000 - val_accuracy: 0.4830 - val_precision: 1.0000 - val_recall: 0.4830 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 76/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 0.5403 - tp: 351.4219 - fp: 135.8186 - tn: 1042.6203 - fn: 374.0042 - accuracy: 0.7315 - precision: 0.7232 - recall: 0.4830 - auc: 0.7755 - prc: 0.7115 - val_loss: 0.7837 - val_tp: 428.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 514.0000 - val_accuracy: 0.4544 - val_precision: 1.0000 - val_recall: 0.4544 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 77/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 0.5390 - tp: 317.1983 - fp: 125.9198 - tn: 1068.0506 - fn: 392.6962 - accuracy: 0.7244 - precision: 0.7067 - recall: 0.4495 - auc: 0.7746 - prc: 0.7013 - val_loss: 0.7550 - val_tp: 453.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 489.0000 - val_accuracy: 0.4809 - val_precision: 1.0000 - val_recall: 0.4809 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 78/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5308 - tp: 339.0084 - fp: 143.0000 - tn: 1044.9578 - fn: 376.8987 - accuracy: 0.7332 - precision: 0.7227 - recall: 0.4902 - auc: 0.7889 - prc: 0.7208 - val_loss: 0.7675 - val_tp: 423.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 519.0000 - val_accuracy: 0.4490 - val_precision: 1.0000 - val_recall: 0.4490 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 79/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 0.5229 - tp: 311.1055 - fp: 117.2194 - tn: 1090.7300 - fn: 384.8101 - accuracy: 0.7399 - precision: 0.7205 - recall: 0.4492 - auc: 0.7860 - prc: 0.7026 - val_loss: 0.7260 - val_tp: 454.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 488.0000 - val_accuracy: 0.4820 - val_precision: 1.0000 - val_recall: 0.4820 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 80/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5382 - tp: 348.1477 - fp: 131.3924 - tn: 1049.3755 - fn: 374.9494 - accuracy: 0.7362 - precision: 0.7304 - recall: 0.4936 - auc: 0.7751 - prc: 0.7200 - val_loss: 0.7896 - val_tp: 403.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 539.0000 - val_accuracy: 0.4278 - val_precision: 1.0000 - val_recall: 0.4278 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 81/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5436 - tp: 319.0717 - fp: 113.0042 - tn: 1079.8439 - fn: 391.9451 - accuracy: 0.7320 - precision: 0.7310 - recall: 0.4442 - auc: 0.7620 - prc: 0.7012 - val_loss: 0.7815 - val_tp: 423.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 519.0000 - val_accuracy: 0.4490 - val_precision: 1.0000 - val_recall: 0.4490 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 82/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 0.5158 - tp: 331.7806 - fp: 108.4895 - tn: 1081.5316 - fn: 382.0633 - accuracy: 0.7487 - precision: 0.7538 - recall: 0.4711 - auc: 0.7972 - prc: 0.7289 - val_loss: 0.7530 - val_tp: 420.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 522.0000 - val_accuracy: 0.4459 - val_precision: 1.0000 - val_recall: 0.4459 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 83/100\n",
      "236/236 [==============================] - 0s 2ms/step - loss: 0.5492 - tp: 326.7215 - fp: 125.6160 - tn: 1057.2447 - fn: 394.2827 - accuracy: 0.7244 - precision: 0.7160 - recall: 0.4525 - auc: 0.7702 - prc: 0.6933 - val_loss: 0.7892 - val_tp: 428.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 514.0000 - val_accuracy: 0.4544 - val_precision: 1.0000 - val_recall: 0.4544 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 84/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5481 - tp: 330.2869 - fp: 126.4557 - tn: 1052.5190 - fn: 394.6034 - accuracy: 0.7279 - precision: 0.7218 - recall: 0.4599 - auc: 0.7697 - prc: 0.7045 - val_loss: 0.7770 - val_tp: 432.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 510.0000 - val_accuracy: 0.4586 - val_precision: 1.0000 - val_recall: 0.4586 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 85/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5407 - tp: 315.0970 - fp: 128.9536 - tn: 1066.2869 - fn: 393.5274 - accuracy: 0.7230 - precision: 0.6976 - recall: 0.4422 - auc: 0.7701 - prc: 0.6919 - val_loss: 0.7492 - val_tp: 445.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 497.0000 - val_accuracy: 0.4724 - val_precision: 1.0000 - val_recall: 0.4724 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 86/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5493 - tp: 316.8734 - fp: 140.0464 - tn: 1046.6920 - fn: 400.2532 - accuracy: 0.7077 - precision: 0.6838 - recall: 0.4304 - auc: 0.7626 - prc: 0.6964 - val_loss: 0.7677 - val_tp: 430.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 512.0000 - val_accuracy: 0.4565 - val_precision: 1.0000 - val_recall: 0.4565 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 87/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5303 - tp: 334.0759 - fp: 132.8861 - tn: 1052.3882 - fn: 384.5148 - accuracy: 0.7308 - precision: 0.7243 - recall: 0.4659 - auc: 0.7910 - prc: 0.7175 - val_loss: 0.7765 - val_tp: 402.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 540.0000 - val_accuracy: 0.4268 - val_precision: 1.0000 - val_recall: 0.4268 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 88/100\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5449 - tp: 331.8945 - fp: 108.2658 - tn: 1069.4641 - fn: 394.2405 - accuracy: 0.7415 - precision: 0.7646 - recall: 0.4555 - auc: 0.7677 - prc: 0.7071 - val_loss: 0.8005 - val_tp: 433.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 509.0000 - val_accuracy: 0.4597 - val_precision: 1.0000 - val_recall: 0.4597 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 89/100\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.5278 - tp: 322.1561 - fp: 119.1983 - tn: 1076.8439 - fn: 385.6667 - accuracy: 0.7368 - precision: 0.7415 - recall: 0.4525 - auc: 0.7877 - prc: 0.7193 - val_loss: 0.7577 - val_tp: 426.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 516.0000 - val_accuracy: 0.4522 - val_precision: 1.0000 - val_recall: 0.4522 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 90/100\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.5184 - tp: 348.7932 - fp: 112.4219 - tn: 1074.5612 - fn: 368.0886 - accuracy: 0.7510 - precision: 0.7706 - recall: 0.4889 - auc: 0.7973 - prc: 0.7415 - val_loss: 0.7644 - val_tp: 412.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 530.0000 - val_accuracy: 0.4374 - val_precision: 1.0000 - val_recall: 0.4374 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 91/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5181 - tp: 336.7511 - fp: 111.8650 - tn: 1078.3376 - fn: 376.9114 - accuracy: 0.7439 - precision: 0.7514 - recall: 0.4722 - auc: 0.7920 - prc: 0.7295 - val_loss: 0.7563 - val_tp: 434.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 508.0000 - val_accuracy: 0.4607 - val_precision: 1.0000 - val_recall: 0.4607 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 92/100\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.5308 - tp: 316.8565 - fp: 118.2068 - tn: 1073.8565 - fn: 394.9451 - accuracy: 0.7351 - precision: 0.7234 - recall: 0.4580 - auc: 0.7804 - prc: 0.7041 - val_loss: 0.7730 - val_tp: 423.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 519.0000 - val_accuracy: 0.4490 - val_precision: 1.0000 - val_recall: 0.4490 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 93/100\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.5318 - tp: 333.5063 - fp: 121.6962 - tn: 1058.8565 - fn: 389.8059 - accuracy: 0.7285 - precision: 0.7320 - recall: 0.4659 - auc: 0.7776 - prc: 0.7247 - val_loss: 0.7990 - val_tp: 422.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 520.0000 - val_accuracy: 0.4480 - val_precision: 1.0000 - val_recall: 0.4480 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 94/100\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.5371 - tp: 328.3671 - fp: 111.0802 - tn: 1074.4219 - fn: 389.9958 - accuracy: 0.7334 - precision: 0.7437 - recall: 0.4528 - auc: 0.7791 - prc: 0.7105 - val_loss: 0.7913 - val_tp: 417.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 525.0000 - val_accuracy: 0.4427 - val_precision: 1.0000 - val_recall: 0.4427 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 95/100\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.5282 - tp: 305.9620 - fp: 108.2743 - tn: 1097.8565 - fn: 391.7722 - accuracy: 0.7390 - precision: 0.7340 - recall: 0.4423 - auc: 0.7794 - prc: 0.7005 - val_loss: 0.7440 - val_tp: 451.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 491.0000 - val_accuracy: 0.4788 - val_precision: 1.0000 - val_recall: 0.4788 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 96/100\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.5335 - tp: 335.4008 - fp: 129.3797 - tn: 1059.0338 - fn: 380.0506 - accuracy: 0.7323 - precision: 0.7192 - recall: 0.4733 - auc: 0.7806 - prc: 0.7145 - val_loss: 0.7753 - val_tp: 421.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 521.0000 - val_accuracy: 0.4469 - val_precision: 1.0000 - val_recall: 0.4469 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 97/100\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.5349 - tp: 324.8439 - fp: 131.8734 - tn: 1061.5527 - fn: 385.5949 - accuracy: 0.7251 - precision: 0.7101 - recall: 0.4403 - auc: 0.7816 - prc: 0.6973 - val_loss: 0.7376 - val_tp: 460.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 482.0000 - val_accuracy: 0.4883 - val_precision: 1.0000 - val_recall: 0.4883 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 98/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5362 - tp: 322.6498 - fp: 127.6793 - tn: 1067.4557 - fn: 386.0802 - accuracy: 0.7255 - precision: 0.7049 - recall: 0.4491 - auc: 0.7766 - prc: 0.6988 - val_loss: 0.7591 - val_tp: 439.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 503.0000 - val_accuracy: 0.4660 - val_precision: 1.0000 - val_recall: 0.4660 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 99/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5349 - tp: 306.8228 - fp: 123.3882 - tn: 1089.3038 - fn: 384.3502 - accuracy: 0.7299 - precision: 0.7025 - recall: 0.4443 - auc: 0.7817 - prc: 0.6787 - val_loss: 0.7314 - val_tp: 445.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 497.0000 - val_accuracy: 0.4724 - val_precision: 1.0000 - val_recall: 0.4724 - val_auc: 0.0000e+00 - val_prc: 1.0000\n",
      "Epoch 100/100\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.5253 - tp: 325.0000 - fp: 129.4599 - tn: 1067.6962 - fn: 381.7089 - accuracy: 0.7369 - precision: 0.7222 - recall: 0.4631 - auc: 0.7896 - prc: 0.7182 - val_loss: 0.7582 - val_tp: 426.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 516.0000 - val_accuracy: 0.4522 - val_precision: 1.0000 - val_recall: 0.4522 - val_auc: 0.0000e+00 - val_prc: 1.0000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbbb459f2b0>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "model = neural_model.simple_nn(METRICS)\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.2, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    " loss, tp, fp, tn, fn, acc, prec, recall, auc, prc = model.evaluate(X_test, y_test, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[0.3765993118286133,\n",
       "  2.0,\n",
       "  7.0,\n",
       "  3510.0,\n",
       "  671.0,\n",
       "  0.8381861448287964,\n",
       "  0.2222222238779068,\n",
       "  0.002971768146380782,\n",
       "  0.7706210017204285,\n",
       "  0.48837658762931824],\n",
       " [0.40408533811569214,\n",
       "  14.0,\n",
       "  10.0,\n",
       "  3507.0,\n",
       "  659.0,\n",
       "  0.8403341174125671,\n",
       "  0.5833333134651184,\n",
       "  0.02080237679183483,\n",
       "  0.7201049327850342,\n",
       "  0.3362295925617218],\n",
       " [0.4155384302139282,\n",
       "  18.0,\n",
       "  9.0,\n",
       "  3507.0,\n",
       "  655.0,\n",
       "  0.8414896130561829,\n",
       "  0.6666666865348816,\n",
       "  0.026745913550257683,\n",
       "  0.6919609308242798,\n",
       "  0.3183708190917969],\n",
       " [0.40109848976135254,\n",
       "  19.0,\n",
       "  6.0,\n",
       "  3510.0,\n",
       "  654.0,\n",
       "  0.8424444794654846,\n",
       "  0.7599999904632568,\n",
       "  0.028231797739863396,\n",
       "  0.7205083966255188,\n",
       "  0.3592396676540375],\n",
       " [0.4066544771194458,\n",
       "  24.0,\n",
       "  9.0,\n",
       "  3507.0,\n",
       "  649.0,\n",
       "  0.8429219126701355,\n",
       "  0.7272727489471436,\n",
       "  0.03566121682524681,\n",
       "  0.7130293250083923,\n",
       "  0.347160667181015]]"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "scores"
   ]
  }
 ]
}